
R version 3.0.1 (2013-05-16) -- "Good Sport"
Copyright (C) 2013 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin10.8.0 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> > options(STERM='iESS', str.dendrogram.last="'", editor='emacsclient', show.error.locations=TRUE)
> library(tseries)

    ‘tseries’ version: 0.10-32

    ‘tseries’ is a package for time series analysis and computational
    finance.

    See ‘library(help="tseries")’ for details.

> data(camp)
> ts <- camp
> 
+ + + . + + . + > 
+ . + > 
+ . + > r <- madlib.arima(ts - mean(ts), 1, 0, 1, include.mean = FALSE, max.iter = 100, tau = 1e-3, e1 = 1e-6, e2 = 1e-6, e3= 1e-6)
... init: phi = [ 0.00445942938327789 ], theta = [ 0.00570551409153268 ], mean =  0 
... iter  1 : phi = [ 0.8712988047665 ], theta = [ -0.177878099245602 ], mean =  0 
... iter  2 : phi = [ 0.862927726033204 ], theta = [ -0.37637995557357 ], mean =  0 
... iter  3 : phi = [ 0.91173506946397 ], theta = [ -0.471763336705452 ], mean =  0 
... iter  4 : phi = [ 0.918864940252899 ], theta = [ -0.502323074832838 ], mean =  0 
... iter  5 : phi = [ 0.922432084972139 ], theta = [ -0.514249796430217 ], mean =  0 
... iter  6 : phi = [ 0.923801644637654 ], theta = [ -0.519049982477082 ], mean =  0 
... iter  7 : phi = [ 0.924359954815072 ], theta = [ -0.521018580262195 ], mean =  0 
... iter  8 : phi = [ 0.924589915078386 ], theta = [ -0.521832049576761 ], mean =  0 
... iter  9 : phi = [ 0.924685110347942 ], theta = [ -0.522169251997012 ], mean =  0 
... iter  10 : phi = [ 0.924724600285063 ], theta = [ -0.522309213033014 ], mean =  0 
... iter  11 : phi = [ 0.924740996221004 ], theta = [ -0.522367337519989 ], mean =  0 
... iter  12 : phi = [ 0.924747806164966 ], theta = [ -0.52239148150586 ], mean =  0 
... iter  13 : phi = [ 0.924750635056929 ], theta = [ -0.522401511471851 ], mean =  0 
... iter  14 : phi = [ 0.924751810269437 ], theta = [ -0.522405678312048 ], mean =  0 
... iter  15 : phi = [ 0.924752298503142 ], theta = [ -0.522407409408429 ], mean =  0 
... iter  16 : phi = [ 0.924752298503142 ], theta = [ -0.522407409408429 ], mean =  0 
> arima(ts - mean(ts), order = c(1,0,1), include.mean = FALSE, method = "CSS")

Call:
arima(x = ts - mean(ts), order = c(1, 0, 1), include.mean = FALSE, method = "CSS")

Coefficients:
         ar1      ma1
      0.9248  -0.5224
s.e.  0.0076   0.0195

sigma^2 estimated as 65.6:  part log likelihood = -18975.32
> arima(ts, order = c(1,0,1), include.mean = FALSE, method = "CSS")

Call:
arima(x = ts, order = c(1, 0, 1), include.mean = FALSE, method = "CSS")

Coefficients:
         ar1      ma1
      0.9975  -0.6182
s.e.  0.0010   0.0148

sigma^2 estimated as 67.54:  part log likelihood = -19054.38
> r <- madlib.arima(ts, 1, 0, 1, include.mean = FALSE, max.iter = 100, tau = 1e-3, e1 = 1e-6, e2 = 1e-6, e3= 1e-6)
... init: phi = [ 0.00905427852179855 ], theta = [ 0.00568650469649583 ], mean =  0 
... iter  1 : phi = [ 0.673754121269521 ], theta = [ 0.313461345938049 ], mean =  0 
... iter  2 : phi = [ 1.09403955747291 ], theta = [ -0.186866191186191 ], mean =  0 
... iter  3 : phi = [ 0.964358428402623 ], theta = [ -0.415190634463765 ], mean =  0 
... iter  4 : phi = [ 1.00288127677289 ], theta = [ -0.544631811560884 ], mean =  0 
... iter  5 : phi = [ 0.996424906004705 ], theta = [ -0.585802083321931 ], mean =  0 
... iter  6 : phi = [ 0.997291648084317 ], theta = [ -0.603632594044816 ], mean =  0 
... iter  7 : phi = [ 0.997375531309636 ], theta = [ -0.61148813718914 ], mean =  0 
... iter  8 : phi = [ 0.997425014538465 ], theta = [ -0.615069371309719 ], mean =  0 
... iter  9 : phi = [ 0.997447463062835 ], theta = [ -0.616724668769423 ], mean =  0 
... iter  10 : phi = [ 0.997457867854833 ], theta = [ -0.61749480648566 ], mean =  0 
... iter  11 : phi = [ 0.997462714469423 ], theta = [ -0.617854218549513 ], mean =  0 
... iter  12 : phi = [ 0.99746497755876 ], theta = [ -0.618022191878972 ], mean =  0 
... iter  13 : phi = [ 0.997466035498537 ], theta = [ -0.618100747964173 ], mean =  0 
... iter  14 : phi = [ 0.997466530324665 ], theta = [ -0.618137497844922 ], mean =  0 
... iter  15 : phi = [ 0.997466761825808 ], theta = [ -0.618154692599214 ], mean =  0 
... iter  16 : phi = [ 0.9974668701448 ], theta = [ -0.61816273833822 ], mean =  0 
... iter  17 : phi = [ 0.997466920829855 ], theta = [ -0.618166503207595 ], mean =  0 
... iter  18 : phi = [ 0.997466944547218 ], theta = [ -0.618168264942016 ], mean =  0 
... iter  19 : phi = [ 0.997466944547218 ], theta = [ -0.618168264942016 ], mean =  0 
> arima(ts, order = c(1,0,1), include.mean = TRUE, method = "CSS")

Call:
arima(x = ts, order = c(1, 0, 1), include.mean = TRUE, method = "CSS")

Coefficients:
         ar1      ma1  intercept
      0.9248  -0.5224    42.2934
s.e.  0.0076   0.0195     0.6993

sigma^2 estimated as 65.6:  part log likelihood = -18975.32
> r <- madlib.arima(ts, 1, 0, 1, include.mean = TRUE, max.iter = 100, tau = 1e-3, e1 = 1e-6, e2 = 1e-6, e3= 1e-6)
... init: phi = [ 0.00220427570864558 ], theta = [ 0.00927169335773215 ], mean =  42.29288 
... iter  1 : phi = [ 0.948435707354843 ], theta = [ -0.25461133475261 ], mean =  42.29288 
... iter  2 : phi = [ 0.866606249575462 ], theta = [ -0.398748198047938 ], mean =  42.29288 
... iter  3 : phi = [ 0.914384239317533 ], theta = [ -0.479640388083692 ], mean =  42.29288 
... iter  4 : phi = [ 0.919743965769515 ], theta = [ -0.505304073765544 ], mean =  42.29288 
... iter  5 : phi = [ 0.922772587583279 ], theta = [ -0.515438166468151 ], mean =  42.29288 
... iter  6 : phi = [ 0.923939541068469 ], theta = [ -0.519535381975391 ], mean =  42.29288 
... iter  7 : phi = [ 0.924416601833915 ], theta = [ -0.52121882209716 ], mean =  42.29288 
... iter  8 : phi = [ 0.924613338842623 ], theta = [ -0.521914996765955 ], mean =  42.29288 
... iter  9 : phi = [ 0.924694822737752 ], theta = [ -0.522203670536534 ], mean =  42.29288 
... iter  10 : phi = [ 0.924728632019524 ], theta = [ -0.522323505006793 ], mean =  42.29288 
... iter  11 : phi = [ 0.924742670640751 ], theta = [ -0.522373273881744 ], mean =  42.29288 
... iter  12 : phi = [ 0.924748501705834 ], theta = [ -0.522393947555654 ], mean =  42.29288 
... iter  13 : phi = [ 0.924750924002917 ], theta = [ -0.522402535956567 ], mean =  42.29288 
... iter  14 : phi = [ 0.924751930309307 ], theta = [ -0.522406103928426 ], mean =  42.29288 
... iter  15 : phi = [ 0.924752348373276 ], theta = [ -0.522407586229903 ], mean =  42.29288 
... iter  16 : phi = [ 0.924752348373276 ], theta = [ -0.522407586229903 ], mean =  42.29288 
> ts <- c(0.723169642966241, 0.038826048374176, 0.496932435780764, 0.0924206441268325, 0.482714195735753, 0.0772823793813586, 0.624092550482601, 0.0157143054530025, 0.851546379737556, 0.267036508303136, 0.249543743208051, 0.048351333476603, 0.900262529496104, 0.610414944123477, 0.684859166387469, 0.199825830757618, 0.867019241675735, 0.718905623536557, 0.221392123959959, 0.757079180330038, 0.645599402021617, 0.341256342362612, 0.51009723637253, 0.238041826989502, 0.66061952104792, 0.316920350305736, 0.155146828852594, 0.318740516901016, 0.735009240917861, 0.541778127662838, 0.786064371932298, 0.458178883884102, 0.580604176037014, 0.282996807713062, 0.550599528010935, 0.0633183717727661, 0.36027918709442, 0.174692078493536, 0.0790326772257686, 0.211825567297637, 0.441728587262332, 0.328576420433819, 0.26017690077424, 0.341991116758436, 0.938991364557296, 0.94503606762737, 0.541816947516054, 0.806010606698692, 0.663941691163927, 0.763209071476012, 0.56308978702873, 0.309541093185544, 0.104465413838625, 0.0731870234012604, 0.547582920640707, 0.765084935352206, 0.390107374172658, 0.702729749493301, 0.0838254522532225, 0.125116615090519, 0.244507877156138, 0.86988982418552, 0.583295499440283, 0.825112053193152, 0.152886632364243, 0.133895027451217, 0.888430425431579, 0.513165819458663, 0.308587106410414, 0.967463102657348, 0.724991386756301, 0.750315693672746, 0.296039523556828, 0.985168287996203, 0.0923068104311824, 0.235030888114125, 0.930204355623573, 0.634123757947236, 0.0410414948128164, 0.5941460467875, 0.397332829423249, 0.604131281841546, 0.903687140438706, 0.501798243261874, 0.677318305708468, 0.451270061079413, 0.26688317861408, 0.0674256798811257, 0.153999810572714, 0.350708630867302, 0.192542294971645, 0.398507688194513, 0.220598455518484, 0.775837794411927, 0.223619741387665, 0.373485087882727, 0.909732822328806, 0.112050166819245, 0.886650907341391, 0.21831992873922, 0.0795132699422538)

  C-c C-c
> 
> 
> ts
Time Series:
Start = -3435 
End = 1969 
Frequency = 1 
   [1] 37 60 71 55 53 78 53 34 54 66 63 64 81 83 82 67 61 63 45 71 67 47 47 45
  [25] 59 58 68 65 74 48 22 48 40 45 33 50 47 43 52 55 41 49 53 59 49 64 64 75
  [49] 63 51 50 55 56 61 55 51 58 58 57 61 61 52 55 60 49 67 71 61 76 87 80 87
  [73] 63 75 68 74 77 81 64 80 60 71 55 77 74 62 46 65 71 24 30 52 68 52 58 68
  [97] 56 58 62 41 48 56 55 56 49 50 55 50 44 60 49 63 56 65 62 67 64 70 58 54
 [121] 37 40 52 61 44 60 63 56 54 70 63 63 77 63 60 47 56 55 55 66 51 51 59 55
 [145] 50 50 56 56 57 48 55 56 45 38 40 41 49 44 51 50 40 60 50 35 28 38 47 49
 [169] 45 57 44 49 47 54 46 57 47 48 49 48 50 55 45 46 55 66 45 49 60 39 40 52
 [193] 53 52 44 52 44 48 50 47 37 46 35 39 43 42 40 49 53 43 48 22 48 43 47 43
 [217] 46 48 38 39 36 40 48 36 45 41 34 41 37 53 54 56 53 65 49 47 50 34 30 45
 [241] 48 47 50 35 60 48 42 43 41 41 51 44 62 50 46 52 50 51 55 53 59 43 56 53
 [265] 49 50 50 53 58 42 54 44 51 51 63 53 45 63 53 59 58 59 48 39 56 53 35 51
 [289] 50 62 49 43 46 41 35 38 43 45 39 52 36 41 38 33 48 51 48 40 45 42 38 43
 [313] 52 42 44 48 46 51 57 44 47 53 42 39 39 42 43 41 49 36 45 43 48 39 42 49
 [337] 35 33 33 40 48 39 44 44 36 47 50 42 39 27 33 36 35 47 48 29 31 37 34 40
 [361] 30 34 42 46 41 39 35 38 33 45 36 37 40 40 38 35 40 27 32 37 42 39 42 24
 [385] 27 30 31 30 36 30 34 38 37 36 32 38 48 32 42 36 33 43 43 30 27 27 39 36
 [409] 37 36 35 38 40 34 37 32 27 33 33 43 36 39 30 31 23 32 34 43 46 41 45 37
 [433] 31 42 48 51 52 39 39 51 36 41 34 40 39 36 44 51 36 37 43 42 47 45 40 41
 [457] 40 32 45 34 39 21 39 46 42 29 35 48 33 27 40 34 33 40 35 29 35 33 34 26
 [481] 30 36 25 32 36 46 28 35 39 35 39 39 36 40 30 38 31 22 37 40 36 27 30 35
 [505] 34 31 46 46 35 33 40 34 31 22 25 26 27 27 26 32 20 24 14 27 26 30 28 23
 [529] 32 34 34 34 39 44 44 32 43 43 38 47 40 35 33 47 47 40 45 37 29 57 51 51
 [553] 50 59 38 59 53 53 52 56 54 40 47 42 44 48 37 40 47 41 42 24 43 46 46 36
 [577] 44 48 40 37 28 38 36 27 25 32 38 40 36 32 33 36 13 31 31 33 37 31 37 41
 [601] 41 40 44 42 48 33 44 43 29 41 30 36 27 35 30 35 36 33 33 34 35 40 32 30
 [625] 33 39 25 41 28 24 23 22 24 20 29 27 29 30 28 22 31 34 28 34 54 46 42 53
 [649] 51 51 42 58 56 50 47 45 49 49 54 46 43 59 66 49 68 75 64 72 66 66 79 74
 [673] 62 65 69 74 56 82 63 55 56 53 54 71 62 46 50 39 47 47 53 46 52 49 56 44
 [697] 48 44 47 59 42 18 53 42 54 51 47 37 49 45 48 50 62 73 70 66 53 57 57 54
 [721] 65 64 59 61 54 57 63 61 72 76 55 62 54 68 42 71 57 67 70 54 74 67 65 56
 [745] 56 54 66 68 37 55 55 61 47  0 27 66 62 53 59 50 54 52 60 51 37 57 43 53
 [769] 49 51 43 62 52 49 49 63 61 60 60 61 65 60 63 61 64 63 54 62 60 54 61 56
 [793] 50 54 51 46 55 54 64 57 50 54 56 50 59 47 51 62 58 56 56 56 41 47 42 42
 [817] 44 50 49 40 50 52 42 57 52 54 58 54 60 57 71 61 61 57 57 64 62 58 49 49
 [841] 44 47 55 46 44 62 62 55 55 51 50 57 61 52 52 47 49 48 48 54 57 52 43 36
 [865] 45 38 44 47 36 43 51 36 48 52 38 45 46 46 50 50 45 45 45 39 40 44 44 54
 [889] 45 45 35 33 39 44 46 39 39 43 50 43 50 48 33 35 39 41 37 36 51 41 45 37
 [913] 45 44 47 36 39 39 26 39 47 40 49 49 47 48 49 53 35 45 45 41 38 39 42 37
 [937] 40 38 36 26 36 32 36 30 37 35 29 35 37 44 43 39 38 39 15 28 37 32 31 45
 [961] 44 40 38 40 44 34 42 32 43 45 40 46 43 39 26 44 41 25 45 46 49 45 39 36
 [985] 44 47 37 32 38 38 37 30 37 38 38 38 40 51 37 36 44 33 44 46 42 45 49 48
[1009] 44 40 43 41 44 31 29 31 45 50 43 48 36 40 43 34 43 48 47 43 51 49 48 47
[1033] 48 53 54 54 42 47 53 43 52 43 28 37 44 49 49 44 44 53 62 49 35 46 47 50
[1057] 51 46 43 36 48 52 57 48 45 33 40 40 40 48 53 51 59 51 54 51 59 58 52 59
[1081] 65 72 53 52 45 51 52 50 58 57 53 57 54 67 46 50 42 41 51 48 45 46 50 54
[1105] 54 55 54 47 49 36 34 44 53 44 28 35 34 41 49 48 41 39 40 37 45 52 45 51
[1129] 43 51 46 58 35 43 48 48 47 44 55 51 20 42 46 58 56 45 52 34 36 40 52 47
[1153] 50 46 41 43 43 56 50 48 51 36 32 38 38 47 40 36 36 36 38 45 30 34 35 41
[1177] 40 41 31 31 40 31 49 43 53 49 54 55 51 62 48 47 54 48 48 38 42 48 25 21
[1201] 39 45 54 43 36 42 38 42 39 38 36 39 38 44 45 44 42 46 46 44 33 51 51 49
[1225] 49 38 43 47 49 53 36 39 43 47 39 37 35 38 37 45 44 44 49 53 61 40 40 49
[1249] 40 54 46 50 44 46 55 39 27 37 33 29 50 37 40 45 36 46 37 55 53 57 60 46
[1273] 53 40 43 49 57 38 35 22 23 36 43 45 46 51 34 39 50 39 45 52 42  0 47 44
[1297] 45 42 56 54 45 47 53 64 41 57 46 55 48 53 62 58 66 67 63 60 63 60 59 48
[1321] 65 60 52 39 29 44 49 53 66 55 51 51 47 49 50 53 53 51 41 43 48 41 51 54
[1345] 55 55 44 55 53 56 62 55 57 43 47 50 45 50 38 48 53 51 48 51 47 45 37 40
[1369] 44 52 51 50 44 51 48 50 47 34 40 46 42 43 51 41 43 43 40 40 43 32 39 34
[1393] 26 40 36 41 51 55 32 30 23 51 52 59 42 49 62 45 52 51 53 50 37 48 44 45
[1417] 51 38 43 36 43 46 46 51 56 59 50 52 47 40 52 43 54 53 52 43 48 32 23 29
[1441] 44 43 53 54 48 47 59 49 53 54 59 48 62 52 56 48 60 60 46 47 57 55 55 61
[1465] 64 53 59 62 58 55 55 39 31 31 39 41 30 43 41 37 42 44 48 48 54 48 44 53
[1489] 50 35 32 28 36 49 48 42 43 43 35 46 41 48 46 43 52 41 42 48 43 41 42 45
[1513] 48 42 37 33 48 34 45 39 32 49 40 32 40 48 46 25 45 51 47 51 45 44 36 47
[1537] 46 45 48 47 47 51 57 58 62 58 57 53 51 56 60 63 47 52 51 50 40 44 50 46
[1561] 47 43 45 43 43 47 41 40 40 36 43 42 41 44 39 37 44 43 33 32 38 29 44 42
[1585] 43 42 38 42 40 34 46 49 50 48 42 45 34 41 42 42 47 51 44 48 36 52 52 45
[1609] 48 46 40 46 50 38 43 49 41 33 42 47 46 37 45 52 44 47 50 45 41 45 42 51
[1633] 56 44 59 49 54 50 48 50 28 20 47 52 36 44 48 38 35 43 40 51 59 53 52 35
[1657] 49 41 46 39 37 48 39 40 32 32 14 31 44 39 42 37 38 43 37 21 41 42 43 51
[1681] 48 48 52 51 50 63 53 59 66 57 52 53 60 47 43 40 36 44 46 42 56 51 42 43
[1705] 45 19 31 41 51 47 43 42 51 44 45 49 48 47 48 59 55 44 50 69 59 45 45 31
[1729] 40 49 34 42 44 40 46 40 40 46 53 51 52 55 31 13 32 41 50 49 50 47 49 57
[1753] 50 52 56 59 49 59 58 58 44 32 43 49 49 53 49 53 48 29 43 46 41 35 44 46
[1777] 39 49 42 48 42 43 39 16 47 37 31 39 32 32 39 42 36 37 21 28 38 40 38 26
[1801] 35 41 45 52 49 47 46 41 38 24 50 52 43 36 45 49 33 37 37 51 47 45 43 47
[1825] 40 42 36 42 31 42 38 47 48 34 44 34 30 41 23 33 29 41 40 44 51 52 48 54
[1849] 33 43 48 42 49 42 42 39 47 48 45 51 55 54 46 48 28 46 52 55 49 47 54 50
[1873] 42 46 46 43 46 23 44 36 50 45 50 54 45 42 34 33 40 41 38 24 53 46 48 55
[1897] 59 47 53 46 50 63 66 55 68 62 55 44 68 60 55 42 60 57 60 44 48 54 37 38
[1921] 61 62 50 49 62 51 57 62 66 63 64 34 37 59 52 60 14 66 81 66 79 66 60 73
[1945] 67 54 57 55 46 21 40 54 53 57 56 59 48 56 58 59 59 51 62 51 59 47 39 44
[1969] 51 53 56 54 48 46 36 34 42 44 48 50 55 60 62 26 55 57 46 52 61 53 51 41
[1993] 56 54 52 59 57 60 57 45 48 45 55 65 59 62 46 48 57 65 56 58 52 55 59 48
[2017] 61 23 56 57 61 62 64 59 55 46 45 48 45 52 52 46 45 50 50 50 42 43 41 44
[2041] 40 36 38 39 42 41 44 45 52 35 21 44 47 39 48 48 52 49 48 60 57 59 48 57
[2065] 60 53 53 47 56 49 61 53 59 53 56 53 50 42 52 55 58 56 57 37 50 44 55 43
[2089] 52 58 62 64 62 52 52 54 48 43 50 60 41 52 62 57 68 79 50 70 57 61 44 47
[2113] 59 40 50 55 56 52 50 44 52 44 48 48 50 51 49 41 58 57 64 59 67 64 53 59
[2137] 70 68 62 70 64 60 29 47 59 64 69 59 64 52 66 57 71 46 56 52 65 65 70 68
[2161] 63 38 71 60 56 28 59 63 52 57 58 51 45 63 61 46 40 50 48 53 20 57 36 45
[2185] 33 46 40 47 49 43 44 38 46 43 40 32 44 43 43 46 49 44 46 42 44 48 40 46
[2209] 41 45 51 45 44 55 54 34 38 52 43 53 35 41 46 30 43 46 38 42 48 39 48 42
[2233] 27 44 45 35 37 47 44 51 37 32 39 41 41 27 31 34 38 35 40 46 44 37 32 31
[2257] 26 37 35 33 36 35 41 25 39 33 41 40 44 35 42 40 36 34 27 28 35 37 41 43
[2281] 35 35 38 33 35 29 38 35 28 23 42 31 40 38 32 33 37 40 40 35 32 33 37 36
[2305] 33 38 40 37 39 43 37 35 37 31 41 34 39 39 39 42 43 39 39 37 41 39 38 36
[2329] 37 32 31 33 30 33 36 38 39 34 32 33 32 32 44 33 26 25 33 39 35 34 26 34
[2353] 27 33 35 37 32 34 38 42 36 30 34 33 23 34 39 34 30 36 39 39 42 39 22 40
[2377] 36 42 40 28 27 25 25 26 25 33 37 39 33 24 35 35 32 37 24 32 34 29 38 37
[2401] 31 39 33 35 47 23 33 25 24 32 34 36 28 30 41 36 38 29 36 38 36 36 39 38
[2425] 37 37 31 31 29 34 40 34 34 38 39 41 35 44 42 46 47 40 32 30 40 37 35 38
[2449] 37 38 37 36 40 40 36 32 34 38 33 35 33 31 38 35 38 38 29 25 28 28 28 30
[2473] 26 26 29 27 26 31 10 22 30 26 20 30 34 34 30 30 32 28 28 24 28 25 31 33
[2497] 31 34 29 34 28 31 34 35 29 31 26 31 32 37 33 35 35 39 30 41 40 38 37 18
[2521] 42 51 56 42 42 48 42 40 46 45 39 39 38 37 38 39 53 44 41 41 16 43 33 42
[2545] 46 19 29 40 34 41 44 34 41 34 37 40 35 50 45 20 30 33 38 39 34 38 28 34
[2569] 32 37 50 35 39 39 36 41 47 43 46 47 17 31 52 22 41 58 54 59 54 49 61 49
[2593] 56 57 43 55 36 40 36 44 32 47 42 36 39 39 30 26 30 31 35 34 38 37 42 42
[2617] 42 35 29 38 23 31 40 36 38 40 35 26 37 31 34 34 36 34 35 36 35 44 44 38
[2641] 24 27 37 36 37 42 35 41 43 43 46 39 37 33 32 34 36 27 15 24 29 27 27 35
[2665] 34 28 29 28 34 36 40 42 45 47 49 48 35 22 37 37 36 50 46 44 51 43 35 48
[2689] 46 53 37 45 50 43 46 38 16 36 45 38 39 39 41 48 43 44 46 51 44 10 35 41
[2713] 36 51 34 43 46 44 36 37 35 43 26 43 44 43 34 41 41 41 42 41 38 44 31 27
[2737] 23 26 40 38 39 33 31 39 42 29 27 26 35 36 47 40 34 34 41 42 39 42 40 36
[2761] 30 23 37 40 38 29 43 23 33 42 39 40 44 44 41 31 31 40 37 40 36 32 37 22
[2785] 37 33 45 42 47 47 46 43 46 43 42 41 40 24  9 31 30 26 32 33 41 34 37 39
[2809] 39 38 15 17 25 32 26 24 30 25 38 40 36 39 40 33 24 32 32 35 37 43 53 37
[2833] 16 36 35 31 40 25 32 37 33 44 39 31 31 34 22 35 34 20 35 25 28 39 34 38
[2857] 36 34 31 31 31 27 41 37 34 30 30 33 23 31 30 33 22 33 12 32 26 19 33 40
[2881] 37 35 41 21 37 27 40 39 36 37 37 31 32 32 34 31 24 17  9 26 16 32 22 31
[2905] 32 34 36 34 38 39 33 37 35 25 36 28 38 40 42 40 30 26 21 33 29 35 17 35
[2929] 30 17 13 38 36 42 38 40 34 36 35 33 35 30 30 35 31 33 37 33 11 29 31 23
[2953]  8 26 31 32 31 30 30 12 27 31 29 25 27 30 25 34 30 33 31 27 26 31 32 35
[2977] 30 29 32 18 27 31 35 38 40 45 36 50 51 46 49 44 62 43 49 53 62 58 56 31
[3001] 55 55 50 47 57 48 49 40 35 44 27 28 34 28 30 29 28 32 43 39 41 34 36 31
[3025] 20 34 36 40 46 23 34 42 34 37 27 31 32 34 33 39 30 33 14 35 45 36 38 35
[3049] 36 24 30 32 24 27 35 31 13 29 36 41 33 42 41 33 48 37 34 45 37 42 29 39
[3073] 46 38 33 17 17 44 39 48 52 33 48 43 46 47 54 40 34 21 43 45 25 37 46 43
[3097] 50 43 10 37 45 40 44 39 50 50 49 30 36 36 11  7 32 38 46 46 43 46 14 39
[3121] 49 35 52 50 44 51 43 51 26 46 49 48 42 44 50 25 44 43 35 45 49 30 46 50
[3145] 50 55 50 52 53 51 55 33 46 28 34 32 38 39 40 42 49 41 46 45 39 35 45 40
[3169] 14 35 37 38 41 40 49 31 40 42 43 42 31 39 35 36 43 29 36 37 37 43 25 37
[3193] 32 39 37 36 29 29 35 44 52 50 47 50 49 36 48 48 44 53 53 48 49 56 58 32
[3217] 49 60 48 60 46 45 54 59 51 46 50 58 46 56 37 55 45 26 41 51 44 38 26 23
[3241] 23 37 36 40 48 42 48 46 49 39 49 41 32 34 26 34 38 40 36 40 40 43 44 39
[3265] 50 19 52 53 58 42 53 37 55 56 50 42 42 48 58 50 55 51 56 49 50 30 39 63
[3289] 55 59 60 53 48 56 44 49 40 47 30 53 54 57 34 29 17 45 48 55 53 44 41 57
[3313] 64 51 58 43 55 55 57 49 43 38 41 43 43 50 36 49 41 29 36 39 40 45 51 49
[3337] 48 53 48 49 56 56 52 42 46 45 40 48 40 35 53 35 50 43 14 43 45 43 41 41
[3361] 40 39 37 33 31 16 37 41 49 49 52 50 24 38 30 50 46 40 43 47 42 50 50 52
[3385] 60 47 52 42 27 43 39 42 41 29 44 35 31 23 28 15 21 39 37 49 51 53 36 36
[3409] 39 33 31 49 45 43 31  7 45 45 47 44 45 55 49 48 51 50 44 42 38 24 35 56
[3433] 62 68 62 58 56 57 66 68 71 68 65 61 56 57 48 54 52 32 16 29 44 48 34 42
[3457] 43 55 60 71 76 80 75 35 64 65 67 57 75 73 72 59 68 64 56 63 39 34 20 29
[3481] 29 42 52 46 57 53 57 31 52 55 43 47 41 43 40 47 44 42 43 38 49 40 57 53
[3505] 58 34 50 49 40 49 57 58 60 56 60 62 63 51 55 32 42 27 53 59 51 54 51 53
[3529] 43 37 54 46 49 45 25 23 21 38 48 47 31 28 44 21 51 51 48 50 50 56 43 28
[3553] 24 27 34 42 33 32 37 39 42 43 46 47 37 28 29 33 40 50 45 42 39 40 38 41
[3577] 43 44 49 49 38 22 34 36 27 19 19 33 39 49 50 56 49 50 41 49 49 47 52 32
[3601] 35 55 54 55 46 55 58 55 32 45 28 48 36 36 47 50 35 44 46 45 43 41 47 46
[3625] 47 56 45 45 48 33 32 36 41 44 35 41 45 47 48 54 63 46 23 43 45 40 52 59
[3649] 48 45 54 56 56 50 44 34 49 32 35 32 27 33 36 44 42 42 44 41 42 16 34 52
[3673] 43 50 57 53 61 55 57 60 46 64 50 52 64 63 69 66 64 38 44 52 59 53 62 51
[3697] 45 50 62 57 61 54 60 57 53 47 39 45 29 45 47 42 39 39 44 57 51 52 53 45
[3721] 57 46 59 51 47 36 47 25 12 37 44 36 36 43 38 35 42 46 43 39 21 24 20 25
[3745] 30 35 33 39 45 43 57 55 53 55 50 18 43 43 43 43 39 44 36 46 46 39 47 42
[3769] 40 44 33 32 44 29 36 33 31 35 26 40 36 41 36 41 43 43 44 47 41 43 44 38
[3793] 46 43 47 42 48 40 49 54 53 47 53 44 32 38 51 44 40 41 34 38 40 46 51 46
[3817] 38 39 34 41 35 29 32 37 37 42 44 43 44 41 44 47 44 45 42 44 19 34 34 43
[3841] 41 45 50 47 51 49 47 52 48 53 41 53 33 28 36 39 41 37 38 49 43 52 51 57
[3865] 60 44 50 65 66 74 55 25 51 35 53 46 23 31 35 34 17 13 28 11 24 21 33 42
[3889] 39 34 36 39 43 42 37 25 43 29 27 33 36 41 46 41 25 16 15 30 19 34 40 48
[3913] 54 38 50 40 31 34 44 42 32 54 31 36 26 30 36 42 41 40 40 37 39 39 36 29
[3937] 40 47 54 51 44 44 49 52 49 41 40 38 33 34 25 29 35 42 47 44 47 49 50 40
[3961] 58 52 39 41 47 38 44 38 45 47 15 23 46 43 37 36 20 26 29 29 32 29 34 38
[3985] 36 36 40 44 36 35 33 44 35 26 35 33  6  4 35 38 36 43 42 18 15 20 30 30
[4009] 27 28 25 23 26 22 21 24 33 30 26 32 34 38 41 41 43 36 46 47 39 40 32 56
[4033] 46 53 46 33 44 34 39 49 53 49 51 57 21 11 24 28 28 20 26 30 45 34 27 40
[4057] 39 42 28 34 25  4 15 20 26 31 33 32 36 43 43 44 49 47 36 30 42 45 39 16
[4081] 32 34 20 35 42 31 47 36 43 41 51 40 42 50 42 41 57 53 47 54 57 47 51 50
[4105] 54 45 60 49 63 60 48 22 46 60 50 31 30 49 37 35 45 34 24 35 35 33 32 25
[4129] 26 24 23 25 22  4 32 35 39 33 43 42 30 18 31 33 39 35 35 28 42 40 42 30
[4153] 19 35 26 33 41 43 43 48 54 59 58 35 39 47 39 31 40 48 42 33 39 29  8 28
[4177] 41 28 30 33 46 51 56 55 56 38 36 49 51 43 56 41 37 45 46 33 12 34 33 40
[4201] 47 40 44 44 28 34 45 42 55 50 54 49 50 54 50 44 39 29 47 52 50 43 30 39
[4225] 34 44 48 28 25 31 33 30 28 18 28 28 30 40 37 41 49 46 32  9 29 33 43 42
[4249] 35 43 44 19 22 26 31 39 42 38 34 30 38 37 37 31 31 27 36 37 28 26 23 22
[4273] 29 21 27 21 35 39 36 30 39 18 25 34 39 35 43 47 45 40 52 40 32 30 25 38
[4297] 35 33 30 24 20 12 14 17 20 23 24 24 25 29 32 25 15 26 23 23 35 24 17 26
[4321] 23 24 19 20 21 29 27 29 34 32 29 35 34 19 22 22 19 21 22 26 17  9 20 21
[4345] 15 19 19 17 18 26 22 19 23 18 21 32 24 23 10 22 26 25 19 31 22 19 16 24
[4369] 25 25 29 33 29 28 28 30 23 29 21 23 24 34 27 22 27 27 23 30 28 23 27  9
[4393] 18 30 24 23 35 37 23 27 35 37 51 33 44 31 34 31 33 28 32 30 34 21 20 27
[4417] 40 32 26 39 41 38 36 47 35 38 37 43 31 15 33 30 36 40 38 36 41 37 34 17
[4441] 28 40 36 31 36 27 41 37 25 30 26 30 35 41 39 36 39 41 46 46 47 39 49 58
[4465] 54 49 40 37 41 51 41 40 46 44 48 46 53 56 41 37 35 55 37 32 34 41 38 30
[4489] 28 24 29 36 33 41 41 48 45 39 33 28 35 32 32 35 34 25 41 41 39 45 46 34
[4513] 33 40 46 60 58 44 61 51 55 47 52 49 58 55 72 46 55 62 83 99 65 72 77 56
[4537] 48 36 50 57 70 64 58 44 44 48 55 32 34 41 46 31 30 29 41 37 41 34 40 47
[4561] 41 38 35 39 50 63 39 22 25 26 25 27 25 27 30 40 41 49 51 44 41 34 28 42
[4585] 43 33 50 45 55 60 66 50 59 72 61 65 65 69 54 70 61 64 70 91 78 76 59 64
[4609] 68 84 87 84 65 64 49 64 72 79 70 56 54 53 53 48 64 49 48 64 64 69 58 68
[4633] 68 60 66 50 56 54 38 44 41 48 44 50 56 67 54 56 56 43 42 29 11 31 44 44
[4657] 51 43 59 56 47 43 51 72 47 57 52 48 44 51 48 38 44 36 40 39 38 39 37 47
[4681] 29 37 55 49 43 48 54 63 32 29 46 52 30 49 47 43 45 42 42 46 43 37 35 34
[4705] 37 35 46 34 38 47 52 48 31 49 45 39 47 46 33 35 38 40 26 36 33 40 45 41
[4729] 45 53 51 41 49 41 48 54 45 37 46 44 47 41 48 36 41 56 52 57 67 53 49 54
[4753] 56 54 56 57 58 43 58 63 61 61 59 57 53 53 38 49 33 39 17 28 23 25 26 25
[4777] 22 28 25 29 34 29 29 30 23 31 37 35 33 32 42 38 32 33 29 26 26 30 35 30
[4801] 33 36 37 39 37 35 41 37 39 40 44 40 36 31 34 48 43 49 38 47 40 40 47 43
[4825] 36 40 43 40 46 49 38 39 32 35 39 34 44 39 42 48 46 36 37 37 34 40 39 39
[4849] 33 37 38 48 33 39 39 41 36 37 41 36 24 37 41 50 39 31 46 51 36 54 48 48
[4873] 34 38 43 33 33 42 34 36 25 31 20 32 18 28 32 34 28 33 23 21 14 13 16 20
[4897] 16 20 19 17 16 16 12 23 26 21 26 25 26 18 35 33 33 26 23 39 29 26 32 33
[4921] 36 31 32 30 38 31 25 32 38 31 23 15 27 39 28 38 34 38 38 36 34 41 36 45
[4945] 55 49 58 55 55 41 54 56 54 49 49 52 43 22 42 51 43 56 58 56 61 56 58 23
[4969] 45 66 55 57 47 55 48 29 14 31 29 24 22 20 26 33 37 34 44 38 41 41 47 43
[4993] 33 38 45 40 50 43 51 40 39 53 54 54 51 33 45 36 43 45 46 46 25 15 19 37
[5017] 35 38 31 35 31 38 39 33 25 34 35 41 51 37 41 43 50 39 31 30 29 47 38 32
[5041] 29 24 43 41 30 31 30 31 39 27 36 38 19 23 24 33 28 27 15 32 18 29 37 44
[5065] 34 33 26 37 43 36 47 45 41 43 48 20 29 34 29 29 31 17 37 37 42 44 38 37
[5089] 34 25 39 40 47 43 49 53 41 46 50 49 41 39 28 24 17 32 25 29 31 19 25 17
[5113] 30 31 32 11 35 31 35 30 19 31 33 32 18 39 35 39 43 41 27 30 29 27 27 28
[5137] 27 13 21 14 24 22 20 33 31 27 35 36 28 37 33 29 38 33 37 49 43 35 43 43
[5161] 35 40 46 46 50 43 52 27 45 35 51 52 45 42 48 54 35 48 43 42 41 53 49 46
[5185] 47 57 40 27 34 38 34 35 46 38 54 52 43 35 33 42 40 43 28 36 35 38 45 42
[5209] 37 47 45 36 41 45 43 28 14 35 34 37 39 37 44 37 35 41 41 41 40 37 47 50
[5233] 44 44 47 56 44 51 48 54 41 40 46 50 26 36 24 30 34 32 32 38 32 32 28 37
[5257] 35 41 33 37 43 42 38 39 40 43 44 42 48 42 24 29 31 37 26 33 27 38 27 33
[5281] 36 31 39 38 30 37 46 41 46 47 38 23 27 35 47 38 43 37 60 37 58 50 54 49
[5305] 54 57 54 55 53 47 36 56 54 51 34 37 54 45 48 41 51 51 58 61 48 57 55 48
[5329] 41 47 32 42 47 22 49 48 52 45 38 44 44 57 47 50 43 54 39 34 49 54 50 43
[5353] 44 56 54 57 61 52 43 63 61 72 72 43 76 71 61 63 72 55 46 63 55 66 66 51
[5377] 60 64 54 56 67 73 52 59 69 70 51 67 61 62 56 59 51 59 32 31 55 57 69 60
[5401] 53 55 64 68 60
> ts <- c(0.723169642966241, 0.038826048374176, 0.496932435780764, 0.0924206441268325, 0.482714195735753, 0.0772823793813586, 0.624092550482601, 0.0157143054530025, 0.851546379737556, 0.267036508303136, 0.249543743208051, 0.048351333476603, 0.900262529496104, 0.610414944123477, 0.684859166387469, 0.199825830757618, 0.867019241675735, 0.718905623536557, 0.221392123959959, 0.757079180330038, 0.645599402021617, 0.341256342362612, 0.51009723637253, 0.238041826989502, 0.66061952104792, 0.316920350305736, 0.155146828852594, 0.318740516901016, 0.735009240917861, 0.541778127662838, 0.786064371932298, 0.458178883884102, 0.580604176037014, 0.282996807713062, 0.550599528010935, 0.0633183717727661, 0.36027918709442, 0.174692078493536, 0.0790326772257686, 0.211825567297637, 0.441728587262332, 0.328576420433819, 0.26017690077424, 0.341991116758436, 0.938991364557296, 0.94503606762737, 0.541816947516054, 0.806010606698692, 0.663941691163927, 0.763209071476012, 0.56308978702873, 0.309541093185544, 0.104465413838625, 0.0731870234012604, 0.547582920640707, 0.765084935352206, 0.390107374172658, 0.702729749493301, 0.0838254522532225, 0.125116615090519, 0.244507877156138, 0.86988982418552, 0.583295499440283, 0.825112053193152, 0.152886632364243, 0.133895027451217, 0.888430425431579, 0.513165819458663, 0.308587106410414, 0.967463102657348, 0.724991386756301, 0.750315693672746, 0.296039523556828, 0.985168287996203, 0.0923068104311824, 0.235030888114125, 0.930204355623573, 0.634123757947236, 0.0410414948128164, 0.5941460467875, 0.397332829423249, 0.604131281841546, 0.903687140438706, 0.501798243261874, 0.677318305708468, 0.451270061079413, 0.26688317861408, 0.0674256798811257, 0.153999810572714, 0.350708630867302, 0.192542294971645, 0.398507688194513, 0.220598455518484, 0.775837794411927, 0.223619741387665, 0.373485087882727, 0.909732822328806, 0.112050166819245, 0.886650907341391, 0.21831992873922, 0.0795132699422538)








  C-c C-c
> 
> 
> ts
Time Series:
Start = -3435 
End = 1969 
Frequency = 1 
   [1] 37 60 71 55 53 78 53 34 54 66 63 64 81 83 82 67 61 63 45 71 67 47 47 45
  [25] 59 58 68 65 74 48 22 48 40 45 33 50 47 43 52 55 41 49 53 59 49 64 64 75
  [49] 63 51 50 55 56 61 55 51 58 58 57 61 61 52 55 60 49 67 71 61 76 87 80 87
  [73] 63 75 68 74 77 81 64 80 60 71 55 77 74 62 46 65 71 24 30 52 68 52 58 68
  [97] 56 58 62 41 48 56 55 56 49 50 55 50 44 60 49 63 56 65 62 67 64 70 58 54
 [121] 37 40 52 61 44 60 63 56 54 70 63 63 77 63 60 47 56 55 55 66 51 51 59 55
 [145] 50 50 56 56 57 48 55 56 45 38 40 41 49 44 51 50 40 60 50 35 28 38 47 49
 [169] 45 57 44 49 47 54 46 57 47 48 49 48 50 55 45 46 55 66 45 49 60 39 40 52
 [193] 53 52 44 52 44 48 50 47 37 46 35 39 43 42 40 49 53 43 48 22 48 43 47 43
 [217] 46 48 38 39 36 40 48 36 45 41 34 41 37 53 54 56 53 65 49 47 50 34 30 45
 [241] 48 47 50 35 60 48 42 43 41 41 51 44 62 50 46 52 50 51 55 53 59 43 56 53
 [265] 49 50 50 53 58 42 54 44 51 51 63 53 45 63 53 59 58 59 48 39 56 53 35 51
 [289] 50 62 49 43 46 41 35 38 43 45 39 52 36 41 38 33 48 51 48 40 45 42 38 43
 [313] 52 42 44 48 46 51 57 44 47 53 42 39 39 42 43 41 49 36 45 43 48 39 42 49
 [337] 35 33 33 40 48 39 44 44 36 47 50 42 39 27 33 36 35 47 48 29 31 37 34 40
 [361] 30 34 42 46 41 39 35 38 33 45 36 37 40 40 38 35 40 27 32 37 42 39 42 24
 [385] 27 30 31 30 36 30 34 38 37 36 32 38 48 32 42 36 33 43 43 30 27 27 39 36
 [409] 37 36 35 38 40 34 37 32 27 33 33 43 36 39 30 31 23 32 34 43 46 41 45 37
 [433] 31 42 48 51 52 39 39 51 36 41 34 40 39 36 44 51 36 37 43 42 47 45 40 41
 [457] 40 32 45 34 39 21 39 46 42 29 35 48 33 27 40 34 33 40 35 29 35 33 34 26
 [481] 30 36 25 32 36 46 28 35 39 35 39 39 36 40 30 38 31 22 37 40 36 27 30 35
 [505] 34 31 46 46 35 33 40 34 31 22 25 26 27 27 26 32 20 24 14 27 26 30 28 23
 [529] 32 34 34 34 39 44 44 32 43 43 38 47 40 35 33 47 47 40 45 37 29 57 51 51
 [553] 50 59 38 59 53 53 52 56 54 40 47 42 44 48 37 40 47 41 42 24 43 46 46 36
 [577] 44 48 40 37 28 38 36 27 25 32 38 40 36 32 33 36 13 31 31 33 37 31 37 41
 [601] 41 40 44 42 48 33 44 43 29 41 30 36 27 35 30 35 36 33 33 34 35 40 32 30
 [625] 33 39 25 41 28 24 23 22 24 20 29 27 29 30 28 22 31 34 28 34 54 46 42 53
 [649] 51 51 42 58 56 50 47 45 49 49 54 46 43 59 66 49 68 75 64 72 66 66 79 74
 [673] 62 65 69 74 56 82 63 55 56 53 54 71 62 46 50 39 47 47 53 46 52 49 56 44
 [697] 48 44 47 59 42 18 53 42 54 51 47 37 49 45 48 50 62 73 70 66 53 57 57 54
 [721] 65 64 59 61 54 57 63 61 72 76 55 62 54 68 42 71 57 67 70 54 74 67 65 56
 [745] 56 54 66 68 37 55 55 61 47  0 27 66 62 53 59 50 54 52 60 51 37 57 43 53
 [769] 49 51 43 62 52 49 49 63 61 60 60 61 65 60 63 61 64 63 54 62 60 54 61 56
 [793] 50 54 51 46 55 54 64 57 50 54 56 50 59 47 51 62 58 56 56 56 41 47 42 42
 [817] 44 50 49 40 50 52 42 57 52 54 58 54 60 57 71 61 61 57 57 64 62 58 49 49
 [841] 44 47 55 46 44 62 62 55 55 51 50 57 61 52 52 47 49 48 48 54 57 52 43 36
 [865] 45 38 44 47 36 43 51 36 48 52 38 45 46 46 50 50 45 45 45 39 40 44 44 54
 [889] 45 45 35 33 39 44 46 39 39 43 50 43 50 48 33 35 39 41 37 36 51 41 45 37
 [913] 45 44 47 36 39 39 26 39 47 40 49 49 47 48 49 53 35 45 45 41 38 39 42 37
 [937] 40 38 36 26 36 32 36 30 37 35 29 35 37 44 43 39 38 39 15 28 37 32 31 45
 [961] 44 40 38 40 44 34 42 32 43 45 40 46 43 39 26 44 41 25 45 46 49 45 39 36
 [985] 44 47 37 32 38 38 37 30 37 38 38 38 40 51 37 36 44 33 44 46 42 45 49 48
[1009] 44 40 43 41 44 31 29 31 45 50 43 48 36 40 43 34 43 48 47 43 51 49 48 47
[1033] 48 53 54 54 42 47 53 43 52 43 28 37 44 49 49 44 44 53 62 49 35 46 47 50
[1057] 51 46 43 36 48 52 57 48 45 33 40 40 40 48 53 51 59 51 54 51 59 58 52 59
[1081] 65 72 53 52 45 51 52 50 58 57 53 57 54 67 46 50 42 41 51 48 45 46 50 54
[1105] 54 55 54 47 49 36 34 44 53 44 28 35 34 41 49 48 41 39 40 37 45 52 45 51
[1129] 43 51 46 58 35 43 48 48 47 44 55 51 20 42 46 58 56 45 52 34 36 40 52 47
[1153] 50 46 41 43 43 56 50 48 51 36 32 38 38 47 40 36 36 36 38 45 30 34 35 41
[1177] 40 41 31 31 40 31 49 43 53 49 54 55 51 62 48 47 54 48 48 38 42 48 25 21
[1201] 39 45 54 43 36 42 38 42 39 38 36 39 38 44 45 44 42 46 46 44 33 51 51 49
[1225] 49 38 43 47 49 53 36 39 43 47 39 37 35 38 37 45 44 44 49 53 61 40 40 49
[1249] 40 54 46 50 44 46 55 39 27 37 33 29 50 37 40 45 36 46 37 55 53 57 60 46
[1273] 53 40 43 49 57 38 35 22 23 36 43 45 46 51 34 39 50 39 45 52 42  0 47 44
[1297] 45 42 56 54 45 47 53 64 41 57 46 55 48 53 62 58 66 67 63 60 63 60 59 48
[1321] 65 60 52 39 29 44 49 53 66 55 51 51 47 49 50 53 53 51 41 43 48 41 51 54
[1345] 55 55 44 55 53 56 62 55 57 43 47 50 45 50 38 48 53 51 48 51 47 45 37 40
[1369] 44 52 51 50 44 51 48 50 47 34 40 46 42 43 51 41 43 43 40 40 43 32 39 34
[1393] 26 40 36 41 51 55 32 30 23 51 52 59 42 49 62 45 52 51 53 50 37 48 44 45
[1417] 51 38 43 36 43 46 46 51 56 59 50 52 47 40 52 43 54 53 52 43 48 32 23 29
[1441] 44 43 53 54 48 47 59 49 53 54 59 48 62 52 56 48 60 60 46 47 57 55 55 61
[1465] 64 53 59 62 58 55 55 39 31 31 39 41 30 43 41 37 42 44 48 48 54 48 44 53
[1489] 50 35 32 28 36 49 48 42 43 43 35 46 41 48 46 43 52 41 42 48 43 41 42 45
[1513] 48 42 37 33 48 34 45 39 32 49 40 32 40 48 46 25 45 51 47 51 45 44 36 47
[1537] 46 45 48 47 47 51 57 58 62 58 57 53 51 56 60 63 47 52 51 50 40 44 50 46
[1561] 47 43 45 43 43 47 41 40 40 36 43 42 41 44 39 37 44 43 33 32 38 29 44 42
[1585] 43 42 38 42 40 34 46 49 50 48 42 45 34 41 42 42 47 51 44 48 36 52 52 45
[1609] 48 46 40 46 50 38 43 49 41 33 42 47 46 37 45 52 44 47 50 45 41 45 42 51
[1633] 56 44 59 49 54 50 48 50 28 20 47 52 36 44 48 38 35 43 40 51 59 53 52 35
[1657] 49 41 46 39 37 48 39 40 32 32 14 31 44 39 42 37 38 43 37 21 41 42 43 51
[1681] 48 48 52 51 50 63 53 59 66 57 52 53 60 47 43 40 36 44 46 42 56 51 42 43
[1705] 45 19 31 41 51 47 43 42 51 44 45 49 48 47 48 59 55 44 50 69 59 45 45 31
[1729] 40 49 34 42 44 40 46 40 40 46 53 51 52 55 31 13 32 41 50 49 50 47 49 57
[1753] 50 52 56 59 49 59 58 58 44 32 43 49 49 53 49 53 48 29 43 46 41 35 44 46
[1777] 39 49 42 48 42 43 39 16 47 37 31 39 32 32 39 42 36 37 21 28 38 40 38 26
[1801] 35 41 45 52 49 47 46 41 38 24 50 52 43 36 45 49 33 37 37 51 47 45 43 47
[1825] 40 42 36 42 31 42 38 47 48 34 44 34 30 41 23 33 29 41 40 44 51 52 48 54
[1849] 33 43 48 42 49 42 42 39 47 48 45 51 55 54 46 48 28 46 52 55 49 47 54 50
[1873] 42 46 46 43 46 23 44 36 50 45 50 54 45 42 34 33 40 41 38 24 53 46 48 55
[1897] 59 47 53 46 50 63 66 55 68 62 55 44 68 60 55 42 60 57 60 44 48 54 37 38
[1921] 61 62 50 49 62 51 57 62 66 63 64 34 37 59 52 60 14 66 81 66 79 66 60 73
[1945] 67 54 57 55 46 21 40 54 53 57 56 59 48 56 58 59 59 51 62 51 59 47 39 44
[1969] 51 53 56 54 48 46 36 34 42 44 48 50 55 60 62 26 55 57 46 52 61 53 51 41
[1993] 56 54 52 59 57 60 57 45 48 45 55 65 59 62 46 48 57 65 56 58 52 55 59 48
[2017] 61 23 56 57 61 62 64 59 55 46 45 48 45 52 52 46 45 50 50 50 42 43 41 44
[2041] 40 36 38 39 42 41 44 45 52 35 21 44 47 39 48 48 52 49 48 60 57 59 48 57
[2065] 60 53 53 47 56 49 61 53 59 53 56 53 50 42 52 55 58 56 57 37 50 44 55 43
[2089] 52 58 62 64 62 52 52 54 48 43 50 60 41 52 62 57 68 79 50 70 57 61 44 47
[2113] 59 40 50 55 56 52 50 44 52 44 48 48 50 51 49 41 58 57 64 59 67 64 53 59
[2137] 70 68 62 70 64 60 29 47 59 64 69 59 64 52 66 57 71 46 56 52 65 65 70 68
[2161] 63 38 71 60 56 28 59 63 52 57 58 51 45 63 61 46 40 50 48 53 20 57 36 45
[2185] 33 46 40 47 49 43 44 38 46 43 40 32 44 43 43 46 49 44 46 42 44 48 40 46
[2209] 41 45 51 45 44 55 54 34 38 52 43 53 35 41 46 30 43 46 38 42 48 39 48 42
[2233] 27 44 45 35 37 47 44 51 37 32 39 41 41 27 31 34 38 35 40 46 44 37 32 31
[2257] 26 37 35 33 36 35 41 25 39 33 41 40 44 35 42 40 36 34 27 28 35 37 41 43
[2281] 35 35 38 33 35 29 38 35 28 23 42 31 40 38 32 33 37 40 40 35 32 33 37 36
[2305] 33 38 40 37 39 43 37 35 37 31 41 34 39 39 39 42 43 39 39 37 41 39 38 36
[2329] 37 32 31 33 30 33 36 38 39 34 32 33 32 32 44 33 26 25 33 39 35 34 26 34
[2353] 27 33 35 37 32 34 38 42 36 30 34 33 23 34 39 34 30 36 39 39 42 39 22 40
[2377] 36 42 40 28 27 25 25 26 25 33 37 39 33 24 35 35 32 37 24 32 34 29 38 37
[2401] 31 39 33 35 47 23 33 25 24 32 34 36 28 30 41 36 38 29 36 38 36 36 39 38
[2425] 37 37 31 31 29 34 40 34 34 38 39 41 35 44 42 46 47 40 32 30 40 37 35 38
[2449] 37 38 37 36 40 40 36 32 34 38 33 35 33 31 38 35 38 38 29 25 28 28 28 30
[2473] 26 26 29 27 26 31 10 22 30 26 20 30 34 34 30 30 32 28 28 24 28 25 31 33
[2497] 31 34 29 34 28 31 34 35 29 31 26 31 32 37 33 35 35 39 30 41 40 38 37 18
[2521] 42 51 56 42 42 48 42 40 46 45 39 39 38 37 38 39 53 44 41 41 16 43 33 42
[2545] 46 19 29 40 34 41 44 34 41 34 37 40 35 50 45 20 30 33 38 39 34 38 28 34
[2569] 32 37 50 35 39 39 36 41 47 43 46 47 17 31 52 22 41 58 54 59 54 49 61 49
[2593] 56 57 43 55 36 40 36 44 32 47 42 36 39 39 30 26 30 31 35 34 38 37 42 42
[2617] 42 35 29 38 23 31 40 36 38 40 35 26 37 31 34 34 36 34 35 36 35 44 44 38
[2641] 24 27 37 36 37 42 35 41 43 43 46 39 37 33 32 34 36 27 15 24 29 27 27 35
[2665] 34 28 29 28 34 36 40 42 45 47 49 48 35 22 37 37 36 50 46 44 51 43 35 48
[2689] 46 53 37 45 50 43 46 38 16 36 45 38 39 39 41 48 43 44 46 51 44 10 35 41
[2713] 36 51 34 43 46 44 36 37 35 43 26 43 44 43 34 41 41 41 42 41 38 44 31 27
[2737] 23 26 40 38 39 33 31 39 42 29 27 26 35 36 47 40 34 34 41 42 39 42 40 36
[2761] 30 23 37 40 38 29 43 23 33 42 39 40 44 44 41 31 31 40 37 40 36 32 37 22
[2785] 37 33 45 42 47 47 46 43 46 43 42 41 40 24  9 31 30 26 32 33 41 34 37 39
[2809] 39 38 15 17 25 32 26 24 30 25 38 40 36 39 40 33 24 32 32 35 37 43 53 37
[2833] 16 36 35 31 40 25 32 37 33 44 39 31 31 34 22 35 34 20 35 25 28 39 34 38
[2857] 36 34 31 31 31 27 41 37 34 30 30 33 23 31 30 33 22 33 12 32 26 19 33 40
[2881] 37 35 41 21 37 27 40 39 36 37 37 31 32 32 34 31 24 17  9 26 16 32 22 31
[2905] 32 34 36 34 38 39 33 37 35 25 36 28 38 40 42 40 30 26 21 33 29 35 17 35
[2929] 30 17 13 38 36 42 38 40 34 36 35 33 35 30 30 35 31 33 37 33 11 29 31 23
[2953]  8 26 31 32 31 30 30 12 27 31 29 25 27 30 25 34 30 33 31 27 26 31 32 35
[2977] 30 29 32 18 27 31 35 38 40 45 36 50 51 46 49 44 62 43 49 53 62 58 56 31
[3001] 55 55 50 47 57 48 49 40 35 44 27 28 34 28 30 29 28 32 43 39 41 34 36 31
[3025] 20 34 36 40 46 23 34 42 34 37 27 31 32 34 33 39 30 33 14 35 45 36 38 35
[3049] 36 24 30 32 24 27 35 31 13 29 36 41 33 42 41 33 48 37 34 45 37 42 29 39
[3073] 46 38 33 17 17 44 39 48 52 33 48 43 46 47 54 40 34 21 43 45 25 37 46 43
[3097] 50 43 10 37 45 40 44 39 50 50 49 30 36 36 11  7 32 38 46 46 43 46 14 39
[3121] 49 35 52 50 44 51 43 51 26 46 49 48 42 44 50 25 44 43 35 45 49 30 46 50
[3145] 50 55 50 52 53 51 55 33 46 28 34 32 38 39 40 42 49 41 46 45 39 35 45 40
[3169] 14 35 37 38 41 40 49 31 40 42 43 42 31 39 35 36 43 29 36 37 37 43 25 37
[3193] 32 39 37 36 29 29 35 44 52 50 47 50 49 36 48 48 44 53 53 48 49 56 58 32
[3217] 49 60 48 60 46 45 54 59 51 46 50 58 46 56 37 55 45 26 41 51 44 38 26 23
[3241] 23 37 36 40 48 42 48 46 49 39 49 41 32 34 26 34 38 40 36 40 40 43 44 39
[3265] 50 19 52 53 58 42 53 37 55 56 50 42 42 48 58 50 55 51 56 49 50 30 39 63
[3289] 55 59 60 53 48 56 44 49 40 47 30 53 54 57 34 29 17 45 48 55 53 44 41 57
[3313] 64 51 58 43 55 55 57 49 43 38 41 43 43 50 36 49 41 29 36 39 40 45 51 49
[3337] 48 53 48 49 56 56 52 42 46 45 40 48 40 35 53 35 50 43 14 43 45 43 41 41
[3361] 40 39 37 33 31 16 37 41 49 49 52 50 24 38 30 50 46 40 43 47 42 50 50 52
[3385] 60 47 52 42 27 43 39 42 41 29 44 35 31 23 28 15 21 39 37 49 51 53 36 36
[3409] 39 33 31 49 45 43 31  7 45 45 47 44 45 55 49 48 51 50 44 42 38 24 35 56
[3433] 62 68 62 58 56 57 66 68 71 68 65 61 56 57 48 54 52 32 16 29 44 48 34 42
[3457] 43 55 60 71 76 80 75 35 64 65 67 57 75 73 72 59 68 64 56 63 39 34 20 29
[3481] 29 42 52 46 57 53 57 31 52 55 43 47 41 43 40 47 44 42 43 38 49 40 57 53
[3505] 58 34 50 49 40 49 57 58 60 56 60 62 63 51 55 32 42 27 53 59 51 54 51 53
[3529] 43 37 54 46 49 45 25 23 21 38 48 47 31 28 44 21 51 51 48 50 50 56 43 28
[3553] 24 27 34 42 33 32 37 39 42 43 46 47 37 28 29 33 40 50 45 42 39 40 38 41
[3577] 43 44 49 49 38 22 34 36 27 19 19 33 39 49 50 56 49 50 41 49 49 47 52 32
[3601] 35 55 54 55 46 55 58 55 32 45 28 48 36 36 47 50 35 44 46 45 43 41 47 46
[3625] 47 56 45 45 48 33 32 36 41 44 35 41 45 47 48 54 63 46 23 43 45 40 52 59
[3649] 48 45 54 56 56 50 44 34 49 32 35 32 27 33 36 44 42 42 44 41 42 16 34 52
[3673] 43 50 57 53 61 55 57 60 46 64 50 52 64 63 69 66 64 38 44 52 59 53 62 51
[3697] 45 50 62 57 61 54 60 57 53 47 39 45 29 45 47 42 39 39 44 57 51 52 53 45
[3721] 57 46 59 51 47 36 47 25 12 37 44 36 36 43 38 35 42 46 43 39 21 24 20 25
[3745] 30 35 33 39 45 43 57 55 53 55 50 18 43 43 43 43 39 44 36 46 46 39 47 42
[3769] 40 44 33 32 44 29 36 33 31 35 26 40 36 41 36 41 43 43 44 47 41 43 44 38
[3793] 46 43 47 42 48 40 49 54 53 47 53 44 32 38 51 44 40 41 34 38 40 46 51 46
[3817] 38 39 34 41 35 29 32 37 37 42 44 43 44 41 44 47 44 45 42 44 19 34 34 43
[3841] 41 45 50 47 51 49 47 52 48 53 41 53 33 28 36 39 41 37 38 49 43 52 51 57
[3865] 60 44 50 65 66 74 55 25 51 35 53 46 23 31 35 34 17 13 28 11 24 21 33 42
[3889] 39 34 36 39 43 42 37 25 43 29 27 33 36 41 46 41 25 16 15 30 19 34 40 48
[3913] 54 38 50 40 31 34 44 42 32 54 31 36 26 30 36 42 41 40 40 37 39 39 36 29
[3937] 40 47 54 51 44 44 49 52 49 41 40 38 33 34 25 29 35 42 47 44 47 49 50 40
[3961] 58 52 39 41 47 38 44 38 45 47 15 23 46 43 37 36 20 26 29 29 32 29 34 38
[3985] 36 36 40 44 36 35 33 44 35 26 35 33  6  4 35 38 36 43 42 18 15 20 30 30
[4009] 27 28 25 23 26 22 21 24 33 30 26 32 34 38 41 41 43 36 46 47 39 40 32 56
[4033] 46 53 46 33 44 34 39 49 53 49 51 57 21 11 24 28 28 20 26 30 45 34 27 40
[4057] 39 42 28 34 25  4 15 20 26 31 33 32 36 43 43 44 49 47 36 30 42 45 39 16
[4081] 32 34 20 35 42 31 47 36 43 41 51 40 42 50 42 41 57 53 47 54 57 47 51 50
[4105] 54 45 60 49 63 60 48 22 46 60 50 31 30 49 37 35 45 34 24 35 35 33 32 25
[4129] 26 24 23 25 22  4 32 35 39 33 43 42 30 18 31 33 39 35 35 28 42 40 42 30
[4153] 19 35 26 33 41 43 43 48 54 59 58 35 39 47 39 31 40 48 42 33 39 29  8 28
[4177] 41 28 30 33 46 51 56 55 56 38 36 49 51 43 56 41 37 45 46 33 12 34 33 40
[4201] 47 40 44 44 28 34 45 42 55 50 54 49 50 54 50 44 39 29 47 52 50 43 30 39
[4225] 34 44 48 28 25 31 33 30 28 18 28 28 30 40 37 41 49 46 32  9 29 33 43 42
[4249] 35 43 44 19 22 26 31 39 42 38 34 30 38 37 37 31 31 27 36 37 28 26 23 22
[4273] 29 21 27 21 35 39 36 30 39 18 25 34 39 35 43 47 45 40 52 40 32 30 25 38
[4297] 35 33 30 24 20 12 14 17 20 23 24 24 25 29 32 25 15 26 23 23 35 24 17 26
[4321] 23 24 19 20 21 29 27 29 34 32 29 35 34 19 22 22 19 21 22 26 17  9 20 21
[4345] 15 19 19 17 18 26 22 19 23 18 21 32 24 23 10 22 26 25 19 31 22 19 16 24
[4369] 25 25 29 33 29 28 28 30 23 29 21 23 24 34 27 22 27 27 23 30 28 23 27  9
[4393] 18 30 24 23 35 37 23 27 35 37 51 33 44 31 34 31 33 28 32 30 34 21 20 27
[4417] 40 32 26 39 41 38 36 47 35 38 37 43 31 15 33 30 36 40 38 36 41 37 34 17
[4441] 28 40 36 31 36 27 41 37 25 30 26 30 35 41 39 36 39 41 46 46 47 39 49 58
[4465] 54 49 40 37 41 51 41 40 46 44 48 46 53 56 41 37 35 55 37 32 34 41 38 30
[4489] 28 24 29 36 33 41 41 48 45 39 33 28 35 32 32 35 34 25 41 41 39 45 46 34
[4513] 33 40 46 60 58 44 61 51 55 47 52 49 58 55 72 46 55 62 83 99 65 72 77 56
[4537] 48 36 50 57 70 64 58 44 44 48 55 32 34 41 46 31 30 29 41 37 41 34 40 47
[4561] 41 38 35 39 50 63 39 22 25 26 25 27 25 27 30 40 41 49 51 44 41 34 28 42
[4585] 43 33 50 45 55 60 66 50 59 72 61 65 65 69 54 70 61 64 70 91 78 76 59 64
[4609] 68 84 87 84 65 64 49 64 72 79 70 56 54 53 53 48 64 49 48 64 64 69 58 68
[4633] 68 60 66 50 56 54 38 44 41 48 44 50 56 67 54 56 56 43 42 29 11 31 44 44
[4657] 51 43 59 56 47 43 51 72 47 57 52 48 44 51 48 38 44 36 40 39 38 39 37 47
[4681] 29 37 55 49 43 48 54 63 32 29 46 52 30 49 47 43 45 42 42 46 43 37 35 34
[4705] 37 35 46 34 38 47 52 48 31 49 45 39 47 46 33 35 38 40 26 36 33 40 45 41
[4729] 45 53 51 41 49 41 48 54 45 37 46 44 47 41 48 36 41 56 52 57 67 53 49 54
[4753] 56 54 56 57 58 43 58 63 61 61 59 57 53 53 38 49 33 39 17 28 23 25 26 25
[4777] 22 28 25 29 34 29 29 30 23 31 37 35 33 32 42 38 32 33 29 26 26 30 35 30
[4801] 33 36 37 39 37 35 41 37 39 40 44 40 36 31 34 48 43 49 38 47 40 40 47 43
[4825] 36 40 43 40 46 49 38 39 32 35 39 34 44 39 42 48 46 36 37 37 34 40 39 39
[4849] 33 37 38 48 33 39 39 41 36 37 41 36 24 37 41 50 39 31 46 51 36 54 48 48
[4873] 34 38 43 33 33 42 34 36 25 31 20 32 18 28 32 34 28 33 23 21 14 13 16 20
[4897] 16 20 19 17 16 16 12 23 26 21 26 25 26 18 35 33 33 26 23 39 29 26 32 33
[4921] 36 31 32 30 38 31 25 32 38 31 23 15 27 39 28 38 34 38 38 36 34 41 36 45
[4945] 55 49 58 55 55 41 54 56 54 49 49 52 43 22 42 51 43 56 58 56 61 56 58 23
[4969] 45 66 55 57 47 55 48 29 14 31 29 24 22 20 26 33 37 34 44 38 41 41 47 43
[4993] 33 38 45 40 50 43 51 40 39 53 54 54 51 33 45 36 43 45 46 46 25 15 19 37
[5017] 35 38 31 35 31 38 39 33 25 34 35 41 51 37 41 43 50 39 31 30 29 47 38 32
[5041] 29 24 43 41 30 31 30 31 39 27 36 38 19 23 24 33 28 27 15 32 18 29 37 44
[5065] 34 33 26 37 43 36 47 45 41 43 48 20 29 34 29 29 31 17 37 37 42 44 38 37
[5089] 34 25 39 40 47 43 49 53 41 46 50 49 41 39 28 24 17 32 25 29 31 19 25 17
[5113] 30 31 32 11 35 31 35 30 19 31 33 32 18 39 35 39 43 41 27 30 29 27 27 28
[5137] 27 13 21 14 24 22 20 33 31 27 35 36 28 37 33 29 38 33 37 49 43 35 43 43
[5161] 35 40 46 46 50 43 52 27 45 35 51 52 45 42 48 54 35 48 43 42 41 53 49 46
[5185] 47 57 40 27 34 38 34 35 46 38 54 52 43 35 33 42 40 43 28 36 35 38 45 42
[5209] 37 47 45 36 41 45 43 28 14 35 34 37 39 37 44 37 35 41 41 41 40 37 47 50
[5233] 44 44 47 56 44 51 48 54 41 40 46 50 26 36 24 30 34 32 32 38 32 32 28 37
[5257] 35 41 33 37 43 42 38 39 40 43 44 42 48 42 24 29 31 37 26 33 27 38 27 33
[5281] 36 31 39 38 30 37 46 41 46 47 38 23 27 35 47 38 43 37 60 37 58 50 54 49
[5305] 54 57 54 55 53 47 36 56 54 51 34 37 54 45 48 41 51 51 58 61 48 57 55 48
[5329] 41 47 32 42 47 22 49 48 52 45 38 44 44 57 47 50 43 54 39 34 49 54 50 43
[5353] 44 56 54 57 61 52 43 63 61 72 72 43 76 71 61 63 72 55 46 63 55 66 66 51
[5377] 60 64 54 56 67 73 52 59 69 70 51 67 61 62 56 59 51 59 32 31 55 57 69 60
[5401] 53 55 64 68 60
> load("ts.rda")
> ts
  [1] 0.72316964 0.03882605 0.49693244 0.09242064 0.48271420 0.07728238
  [7] 0.62409255 0.01571431 0.85154638 0.26703651 0.24954374 0.04835133
 [13] 0.90026253 0.61041494 0.68485917 0.19982583 0.86701924 0.71890562
 [19] 0.22139212 0.75707918 0.64559940 0.34125634 0.51009724 0.23804183
 [25] 0.66061952 0.31692035 0.15514683 0.31874052 0.73500924 0.54177813
 [31] 0.78606437 0.45817888 0.58060418 0.28299681 0.55059953 0.06331837
 [37] 0.36027919 0.17469208 0.07903268 0.21182557 0.44172859 0.32857642
 [43] 0.26017690 0.34199112 0.93899136 0.94503607 0.54181695 0.80601061
 [49] 0.66394169 0.76320907 0.56308979 0.30954109 0.10446541 0.07318702
 [55] 0.54758292 0.76508494 0.39010737 0.70272975 0.08382545 0.12511662
 [61] 0.24450788 0.86988982 0.58329550 0.82511205 0.15288663 0.13389503
 [67] 0.88843043 0.51316582 0.30858711 0.96746310 0.72499139 0.75031569
 [73] 0.29603952 0.98516829 0.09230681 0.23503089 0.93020436 0.63412376
 [79] 0.04104149 0.59414605 0.39733283 0.60413128 0.90368714 0.50179824
 [85] 0.67731831 0.45127006 0.26688318 0.06742568 0.15399981 0.35070863
 [91] 0.19254229 0.39850769 0.22059846 0.77583779 0.22361974 0.37348509
 [97] 0.90973282 0.11205017 0.88665091 0.21831993 0.07951327
> mean(ts)
[1] 0.4571328
> arima(ts, order = c(1,0,1), include.mean = TRUE, method = "CSS")

Call:
arima(x = ts, order = c(1, 0, 1), include.mean = TRUE, method = "CSS")

Coefficients:
          ar1     ma1  intercept
      -0.9410  0.9513     0.4519
s.e.   0.0203  0.0342     0.0261

sigma^2 estimated as 0.07217:  part log likelihood = -10.56
> arima(ts, order = c(2,0,1), include.mean = TRUE, method = "CSS")

Call:
arima(x = ts, order = c(2, 0, 1), include.mean = TRUE, method = "CSS")

Coefficients:
          ar1     ar2     ma1  intercept
      -0.8437  0.0673  0.9263     0.4524
s.e.   0.1062  0.0993  0.0436     0.0285

sigma^2 estimated as 0.07259:  part log likelihood = -10.85
> arima(ts, order = c(2,0,2), include.mean = TRUE, method = "CSS")

Call:
arima(x = ts, order = c(2, 0, 2), include.mean = TRUE, method = "CSS")

Coefficients:
          ar1     ar2      ma1      ma2  intercept
      -0.0013  0.8573  -0.1063  -1.0009     0.4623
s.e.   0.0058  0.0240   0.0313   0.0356        NaN

sigma^2 estimated as 0.064:  part log likelihood = -4.49
Warning message:
In sqrt(diag(x$var.coef)) : NaNs produced
> arima(ts, order = c(3,0,1), include.mean = TRUE, method = "CSS")

Call:
arima(x = ts, order = c(3, 0, 1), include.mean = TRUE, method = "CSS")

Coefficients:
          ar1     ar2      ar3     ma1  intercept
      -0.8331  0.1030  -0.0155  0.9231     0.4455
s.e.   0.1107  0.1346   0.1015  0.0616     0.0299

sigma^2 estimated as 0.07584:  part log likelihood = -13.07
> r <- madlib.arima(ts, 3, 0, 1, include.mean = TRUE, max.iter = 100, tau = 1e-3, e1 = 1e-6, e2 = 1e-6, e3= 1e-6)
... init: phi = [ 0.00784882852109149, 0.00288633565185592, 0.00383608881151304 ], theta = [ 0.00908022327814251 ], mean =  0.4571328 
... iter  1 : phi = [ -0.784332825732484, 0.111471472660526, 0.00141118026831387 ], theta = [ 0.771023413494316 ], mean =  0.4571328 
... iter  2 : phi = [ -0.843242720416037, 0.0964663833767348, 0.0168291591994034 ], theta = [ 0.906220219910625 ], mean =  0.4571328 
... iter  3 : phi = [ -0.859094859622941, 0.108709219258767, -0.00735758261592857 ], theta = [ 0.946052285771932 ], mean =  0.4571328 
... iter  4 : phi = [ -0.823460936026627, 0.101771641305786, -0.0195684655338428 ], theta = [ 0.911302968462677 ], mean =  0.4571328 
... iter  5 : phi = [ -0.833252667892319, 0.103678436630583, -0.0177329357531001 ], theta = [ 0.924001791818317 ], mean =  0.4571328 
... iter  6 : phi = [ -0.828419635632825, 0.102253796792793, -0.0184829734743674 ], theta = [ 0.917005762709498 ], mean =  0.4571328 
... iter  7 : phi = [ -0.831267355870783, 0.102850586096667, -0.0180328986844924 ], theta = [ 0.920806963521236 ], mean =  0.4571328 
... iter  8 : phi = [ -0.829951808664595, 0.102424743309268, -0.018206969211583 ], theta = [ 0.918832585386975 ], mean =  0.4571328 
... iter  9 : phi = [ -0.830697150578735, 0.102582024282275, -0.0181144581125867 ], theta = [ 0.91984934942287 ], mean =  0.4571328 
... iter  10 : phi = [ -0.830367531084316, 0.102464448874981, -0.018157963597479 ], theta = [ 0.919344221865554 ], mean =  0.4571328 
... iter  11 : phi = [ -0.830548288984066, 0.102499535576051, -0.0181419841089699 ], theta = [ 0.91959287887607 ], mean =  0.4571328 
... iter  12 : phi = [ -0.83047222390571, 0.102468269291281, -0.0181532220023659 ], theta = [ 0.919473217221504 ], mean =  0.4571328 
... iter  13 : phi = [ -0.83051404152973, 0.102474455176232, -0.0181513189253193 ], theta = [ 0.919530178311019 ], mean =  0.4571328 
... iter  14 : phi = [ -0.830497783092901, 0.102466054677252, -0.0181544120460196 ], theta = [ 0.919503403660453 ], mean =  0.4571328 
... iter  15 : phi = [ -0.830507260155644, 0.102466548966496, -0.0181545614615523 ], theta = [ 0.91951582988991 ], mean =  0.4571328 
... iter  16 : phi = [ -0.830504073338786, 0.102464158853209, -0.0181555050824619 ], theta = [ 0.919510079393477 ], mean =  0.4571328 
... iter  17 : phi = [ -0.83050625008373, 0.1024638895701, -0.0181557459759046 ], theta = [ 0.91951269854048 ], mean =  0.4571328 
... iter  18 : phi = [ -0.830505705986389, 0.102463143622418, -0.0181560682955365 ], theta = [ 0.919511492192432 ], mean =  0.4571328 
... iter  19 : phi = [ -0.830505705986389, 0.102463143622418, -0.0181560682955365 ], theta = [ 0.919511492192432 ], mean =  0.4571328 
> r <- madlib.arima(ts - 0.4455, 3, 0, 1, include.mean = FALSE, max.iter = 100, tau = 1e-3, e1 = 1e-6, e2 = 1e-6, e3= 1e-6)
... init: phi = [ 0.00227030754089355, 0.00554645483847708, 0.00985653477022424 ], theta = [ 0.0063920483738184 ], mean =  0 
... iter  1 : phi = [ -0.724679185425863, 0.107454481984368, 0.0049043737534715 ], theta = [ 0.713512976561636 ], mean =  0 
... iter  2 : phi = [ -0.79131189399823, 0.0987623494792032, 0.0104505709981458 ], theta = [ 0.841761024424663 ], mean =  0 
... iter  3 : phi = [ -0.867697205594907, 0.111702851690146, -0.00394858085460343 ], theta = [ 0.951875878145276 ], mean =  0 
... iter  4 : phi = [ -0.822933237052805, 0.103164553752867, -0.0214354163072676 ], theta = [ 0.916233022514624 ], mean =  0 
... iter  5 : phi = [ -0.834737390639496, 0.104043583544107, -0.0158297831825426 ], theta = [ 0.927127133689601 ], mean =  0 
... iter  6 : phi = [ -0.830156741514938, 0.102707953896185, -0.0163971496833027 ], theta = [ 0.920113803947439 ], mean =  0 
... iter  7 : phi = [ -0.834368738844021, 0.103462159372327, -0.0153202815975447 ], theta = [ 0.925164503564131 ], mean =  0 
... iter  8 : phi = [ -0.832195462817523, 0.102822075427235, -0.0156313296324653 ], theta = [ 0.92194963060392 ], mean =  0 
... iter  9 : phi = [ -0.83353480758576, 0.103149056143269, -0.0154387422750369 ], theta = [ 0.923802433542294 ], mean =  0 
... iter  10 : phi = [ -0.832859270108437, 0.102929670395275, -0.0155132275467898 ], theta = [ 0.922774068156604 ], mean =  0 
... iter  11 : phi = [ -0.833242871090655, 0.103029202173674, -0.0154741666531263 ], theta = [ 0.923326154099819 ], mean =  0 
... iter  12 : phi = [ -0.833058559770269, 0.102964278670608, -0.0154917106147969 ], theta = [ 0.923039185263892 ], mean =  0 
... iter  13 : phi = [ -0.833158792944377, 0.102990085008842, -0.0154847580314802 ], theta = [ 0.923185890429912 ], mean =  0 
... iter  14 : phi = [ -0.833112823293126, 0.102972219302383, -0.0154890332613871 ], theta = [ 0.923112658453817 ], mean =  0 
... iter  15 : phi = [ -0.833137466220776, 0.102978010632108, -0.01548813344299 ], theta = [ 0.923148780983831 ], mean =  0 
... iter  16 : phi = [ -0.833126812010055, 0.10297320658135, -0.0154892726510066 ], theta = [ 0.923131262924021 ], mean =  0 
... iter  17 : phi = [ -0.833132651211808, 0.102974251417283, -0.0154893067513451 ], theta = [ 0.923139672684852 ], mean =  0 
... iter  18 : phi = [ -0.833130353687584, 0.102972926239625, -0.0154896568619816 ], theta = [ 0.923135681048653 ], mean =  0 
... iter  19 : phi = [ -0.833131722936831, 0.102973012997627, -0.0154897536913632 ], theta = [ 0.923137557566112 ], mean =  0 
... iter  20 : phi = [ -0.833131722936831, 0.102973012997627, -0.0154897536913632 ], theta = [ 0.923137557566112 ], mean =  0 
> 
+ + . + + . + > r <- madlib.arima(ts, 3, 0, 1, include.mean = TRUE, max.iter = 100, tau = 1e-3, e1 = 1e-6, e2 = 1e-6, e3= 1e-6)
... init: phi = [ 0.00940602895105258, 0.00940628526965156, 0.00404074471211061 ], theta = [ 0.00838080551475287 ], mean =  0.4571328 
... iter  1 : phi = [ -0.76087040710244, 0.111853212102099, 0.00605865425238198 ], theta = [ 0.747523189170979 ], mean =  0.4571328 
... iter  2 : phi = [ -0.822516651446988, 0.097493332969267, 0.0131837726594663 ], theta = [ 0.879204382050911 ], mean =  0.4571328 
... iter  3 : phi = [ -0.828433269700289, 0.106992029513409, -0.00497534967724877 ], theta = [ 0.897990942740044 ], mean =  0.4571328 
... iter  4 : phi = [ -0.836852589267994, 0.107767198362468, -0.01092179775677 ], theta = [ 0.924290708312442 ], mean =  0.4571328 
... iter  5 : phi = [ -0.829625315476436, 0.104707054229844, -0.0151648974646308 ], theta = [ 0.917308173776971 ], mean =  0.4571328 
... iter  6 : phi = [ -0.831278728627625, 0.104334816629948, -0.0165010788518336 ], theta = [ 0.920731035275763 ], mean =  0.4571328 
... iter  7 : phi = [ -0.829932269860523, 0.103379258946264, -0.0173895634709371 ], theta = [ 0.91899361762355 ], mean =  0.4571328 
... iter  8 : phi = [ -0.830507110043247, 0.103151964618585, -0.0176940002727864 ], theta = [ 0.919808525928797 ], mean =  0.4571328 
... iter  9 : phi = [ -0.830267437863685, 0.102832390422187, -0.0179178156430622 ], theta = [ 0.919387544623096 ], mean =  0.4571328 
... iter  10 : phi = [ -0.830449853298753, 0.102721728448001, -0.018006129282329 ], theta = [ 0.91958402093345 ], mean =  0.4571328 
... iter  11 : phi = [ -0.830415697138134, 0.102609560252793, -0.0180727153402825 ], theta = [ 0.9194823040296 ], mean =  0.4571328 
... iter  12 : phi = [ -0.83047363874738, 0.102560632186775, -0.0181031643619633 ], theta = [ 0.919529960480676 ], mean =  0.4571328 
... iter  13 : phi = [ -0.830472678529427, 0.10251874438458, -0.0181263774181402 ], theta = [ 0.919504263904811 ], mean =  0.4571328 
... iter  14 : phi = [ -0.830494302457014, 0.10249666185716, -0.0181380311025485 ], theta = [ 0.919517800226199 ], mean =  0.4571328 
... iter  15 : phi = [ -0.83049468063736, 0.102479783223567, -0.018147767547927 ], theta = [ 0.919508525489313 ], mean =  0.4571328 
... iter  16 : phi = [ -0.830504402754172, 0.102471808482533, -0.0181511245377096 ], theta = [ 0.919514984754341 ], mean =  0.4571328 
... iter  17 : phi = [ -0.830502303677418, 0.102466532292891, -0.018154641107264 ], theta = [ 0.919509680789835 ], mean =  0.4571328 
... iter  18 : phi = [ -0.83050675998307, 0.102464852533732, -0.0181549367888056 ], theta = [ 0.91951369018397 ], mean =  0.4571328 
... iter  19 : phi = [ -0.830504774082376, 0.102463295186452, -0.0181561587315351 ], theta = [ 0.919510564170559 ], mean =  0.4571328 
... iter  20 : phi = [ -0.830506769023115, 0.102463103816289, -0.0181560294954165 ], theta = [ 0.919512749564121 ], mean =  0.4571328 
... iter  21 : phi = [ -0.830505829655346, 0.102462592266299, -0.0181563922444176 ], theta = [ 0.919511323440367 ], mean =  0.4571328 
... iter  22 : phi = [ -0.830505829655346, 0.102462592266299, -0.0181563922444176 ], theta = [ 0.919511323440367 ], mean =  0.4571328 
> r
$phi
[1] -0.83050583  0.10246259 -0.01815639

$theta
[1] 0.9195113

$mu
[1] 0.4571328

$mz
[1] 0.0009732461

> arima(ts, order = c(3,0,1), include.mean = TRUE, method = "CSS")

Call:
arima(x = ts, order = c(3, 0, 1), include.mean = TRUE, method = "CSS")

Coefficients:
          ar1     ar2      ar3     ma1  intercept
      -0.8331  0.1030  -0.0155  0.9231     0.4455
s.e.   0.1107  0.1346   0.1015  0.0616     0.0299

sigma^2 estimated as 0.07584:  part log likelihood = -13.07
> (1+0.9195113) / (1 + 0.83050583 - 0.10246259 + 0.01815639)
[1] 1.099251
> 0.4571328 - 0.4455
[1] 0.0116328
> 1.099251 * 0.0009732461
[1] 0.001069842
> mean(ts)
[1] 0.4571328
> 
+ + + . + + . + > r <- madlib.arima(ts, 3, 0, 1, include.mean = TRUE, max.iter = 100, tau = 1e-3, e1 = 1e-6, e2 = 1e-6, e3= 1e-6)
... init: phi = [ 0.00197442225180566, 0.00351935686077923, 0.000786862620152533 ], theta = [ 0.00395714873448014 ], mean =  0.4571328 
... iter  1 : phi = [ -0.767833044811292, 0.103116029107317, 0.00153345332870117 ], theta = [ 0.754431116365351 ], mean =  0.4571328 
... iter  2 : phi = [ -0.829990360732126, 0.095474546817045, 0.011255508814124 ], theta = [ 0.88765305563038 ], mean =  0.4571328 
... iter  3 : phi = [ -0.834940975574905, 0.104830091163213, -0.00574849880451824 ], theta = [ 0.905696733344373 ], mean =  0.4571328 
... iter  4 : phi = [ -0.837532835709506, 0.105436366039175, -0.0117729773490695 ], theta = [ 0.923360474254193 ], mean =  0.4571328 
... iter  5 : phi = [ -0.830538981878071, 0.103438360150691, -0.0158237096820262 ], theta = [ 0.917651941378238 ], mean =  0.4571328 
... iter  6 : phi = [ -0.831637111144884, 0.103451162498562, -0.0169412007308122 ], theta = [ 0.920614414230964 ], mean =  0.4571328 
... iter  7 : phi = [ -0.830185815384647, 0.102840611528033, -0.0176949072888486 ], theta = [ 0.918996496362036 ], mean =  0.4571328 
... iter  8 : phi = [ -0.830676494409216, 0.102806419679553, -0.0178771478084134 ], theta = [ 0.919809311235894 ], mean =  0.4571328 
... iter  9 : phi = [ -0.830359988734061, 0.102612202471451, -0.0180392137247052 ], theta = [ 0.919371671861577 ], mean =  0.4571328 
... iter  10 : phi = [ -0.830521893139585, 0.102585206456954, -0.0180784539865661 ], theta = [ 0.919590030555959 ], mean =  0.4571328 
... iter  11 : phi = [ -0.830453388742308, 0.102521952432647, -0.0181194169585869 ], theta = [ 0.919475395671577 ], mean =  0.4571328 
... iter  12 : phi = [ -0.830501995923801, 0.102507157726644, -0.0181312515869022 ], theta = [ 0.919532033050581 ], mean =  0.4571328 
... iter  13 : phi = [ -0.830488046120511, 0.102485866581408, -0.0181433297670676 ], theta = [ 0.919502595034831 ], mean =  0.4571328 
... iter  14 : phi = [ -0.830502462396755, 0.102478920076064, -0.0181476347601996 ], theta = [ 0.919517070116866 ], mean =  0.4571328 
... iter  15 : phi = [ -0.830500034324492, 0.102471512171248, -0.0181515925916264 ], theta = [ 0.919509527569013 ], mean =  0.4571328 
... iter  16 : phi = [ -0.83050439405342, 0.102468517439814, -0.01815326415765 ], theta = [ 0.91951321978197 ], mean =  0.4571328 
... iter  17 : phi = [ -0.830504161507959, 0.102465857184777, -0.0181546557255018 ], theta = [ 0.919511265490422 ], mean =  0.4571328 
... iter  18 : phi = [ -0.830505588151257, 0.102464583057827, -0.0181553205049601 ], theta = [ 0.91951225125665 ], mean =  0.4571328 
... iter  19 : phi = [ -0.830505620881011, 0.102463562269329, -0.0181558721745357 ], theta = [ 0.919511665415074 ], mean =  0.4571328 
... iter  20 : phi = [ -0.830505620881011, 0.102463562269329, -0.0181558721745357 ], theta = [ 0.919511665415074 ], mean =  0.4571328 
> length(ts)
[1] 101
> length(r$z)
[1] 98
> mean(z)
Error in mean(z) : object 'z' not found
> mean(r$z)
[1] 0.0009732426
> sd(z)
Error in is.data.frame(x) : object 'z' not found
> sd(r$z)
[1] 0.2770219
> hist(r$z)
> arima(ts, order = c(1,0,1), include.mean = TRUE, method = "CSS")

Call:
arima(x = ts, order = c(1, 0, 1), include.mean = TRUE, method = "CSS")

Coefficients:
          ar1     ma1  intercept
      -0.9410  0.9513     0.4519
s.e.   0.0203  0.0342     0.0261

sigma^2 estimated as 0.07217:  part log likelihood = -10.56
> r <- madlib.arima(ts, 1, 0, 1, include.mean = TRUE, max.iter = 100, tau = 1e-3, e1 = 1e-6, e2 = 1e-6, e3= 1e-6)
... init: phi = [ 0.00629139700671658 ], theta = [ 0.00497283551609144 ], mean =  0.4571328 
... iter  1 : phi = [ -0.764330668922712 ], theta = [ 0.73989542840108 ], mean =  0.4571328 
... iter  2 : phi = [ -0.823289227530728 ], theta = [ 0.787727355815899 ], mean =  0.4571328 
... iter  3 : phi = [ -0.96155340378672 ], theta = [ 0.96411663732408 ], mean =  0.4571328 
... iter  4 : phi = [ -0.94064772054305 ], theta = [ 0.945043740909777 ], mean =  0.4571328 
... iter  5 : phi = [ -0.944344079693556 ], theta = [ 0.955006344451555 ], mean =  0.4571328 
... iter  6 : phi = [ -0.940184071641221 ], theta = [ 0.948951026950573 ], mean =  0.4571328 
... iter  7 : phi = [ -0.943282562541023 ], theta = [ 0.953826002937467 ], mean =  0.4571328 
... iter  8 : phi = [ -0.940761906965747 ], theta = [ 0.949956351177304 ], mean =  0.4571328 
... iter  9 : phi = [ -0.942687476395873 ], theta = [ 0.952902766788691 ], mean =  0.4571328 
... iter  10 : phi = [ -0.941186684947226 ], theta = [ 0.950599287519141 ], mean =  0.4571328 
... iter  11 : phi = [ -0.942312918598877 ], theta = [ 0.952312999994363 ], mean =  0.4571328 
... iter  12 : phi = [ -0.941465288315285 ], theta = [ 0.951020120189991 ], mean =  0.4571328 
... iter  13 : phi = [ -0.942084644987701 ], theta = [ 0.951957833137323 ], mean =  0.4571328 
... iter  14 : phi = [ -0.94163457509055 ], theta = [ 0.951276174977768 ], mean =  0.4571328 
... iter  15 : phi = [ -0.941953938715169 ], theta = [ 0.951757059146006 ], mean =  0.4571328 
... iter  16 : phi = [ -0.941729589871819 ], theta = [ 0.951419601273502 ], mean =  0.4571328 
... iter  17 : phi = [ -0.941884153065946 ], theta = [ 0.951651036576426 ], mean =  0.4571328 
... iter  18 : phi = [ -0.941778939657023 ], theta = [ 0.951493784989533 ], mean =  0.4571328 
... iter  19 : phi = [ -0.941849402101064 ], theta = [ 0.951598718691587 ], mean =  0.4571328 
... iter  20 : phi = [ -0.941802792251983 ], theta = [ 0.951529456826346 ], mean =  0.4571328 
... iter  21 : phi = [ -0.941833196432675 ], theta = [ 0.951574503615423 ], mean =  0.4571328 
... iter  22 : phi = [ -0.94181359692885 ], theta = [ 0.95154552924952 ], mean =  0.4571328 
... iter  23 : phi = [ -0.941826078284302 ], theta = [ 0.951563934395063 ], mean =  0.4571328 
... iter  24 : phi = [ -0.941818216603532 ], theta = [ 0.951552366030563 ], mean =  0.4571328 
... iter  25 : phi = [ -0.941823115323312 ], theta = [ 0.951559558668747 ], mean =  0.4571328 
... iter  26 : phi = [ -0.94182009323036 ], theta = [ 0.951555130149969 ], mean =  0.4571328 
... iter  27 : phi = [ -0.941821939718275 ], theta = [ 0.95155783070798 ], mean =  0.4571328 
... iter  28 : phi = [ -0.941820821699648 ], theta = [ 0.951556198508872 ], mean =  0.4571328 
... iter  29 : phi = [ -0.941820821699648 ], theta = [ 0.951556198508872 ], mean =  0.4571328 
> (1 + 0.951556198508872) / ( 1 + 0.94182009323036)
[1] 1.005014
> mean(r$z)
[1] -0.001372621
> mean(ts) + 1.005014 * 0.001372621
[1] 0.4585123
> sd(r$z)
[1] 0.2700551
> var(r$z)
[1] 0.07292974
> s <- arima(ts, order = c(1,0,1), include.mean = TRUE, method = "CSS")
> length(s$residuals)
[1] 101
> mean(resid(s))
[1] 0.003838196
> var(resid(s))
[1] 0.07215853
> var(resid(s)) * 101/100
[1] 0.07288012
> var(resid(s)) * 100/101
[1] 0.07144409
> s$coef
       ar1        ma1  intercept 
-0.9410153  0.9512990  0.4518814 
> s$coef[1]
       ar1 
-0.9410153 
> (1 + s$coef[2]) / (1 - s$coef[1]) 
     ma1 
1.005298 
> mean(ts) - mean(resid(s)) * (1 + s$coef[2]) / (1 - s$coef[1]) 
      ma1 
0.4532743 
> var(resid(s)) * 100/99
[1] 0.07288741
> var(resid(s)) * 110/109
[1] 0.07282054
> var(resid(s))
[1] 0.07215853
> s$var.coef
                    ar1           ma1     intercept
ar1        0.0004104068 -2.258357e-04 -1.053847e-04
ma1       -0.0002258357  1.167355e-03  3.255416e-05
intercept -0.0001053847  3.255416e-05  6.813020e-04
> s$sigma2
[1] 0.07217341
> var(resid(s))/s$sigma2
[1] 0.9997938
> 1 %+% c(1,-1)
Error: could not find function "%+%"
> mean(ts) * (1 - s$coef[1])
      ar1 
0.8873018 
> 
+ + . + + . + > 
+ . + > 
+ + . + > r <- madlib.arima(ts, 1, 0, 1, include.mean = TRUE, max.iter = 100, tau = 1e-3, e1 = 1e-6, e2 = 1e-6, e3= 1e-6)
... init: phi = [ 0.00526872175047174 ], theta = [ 0.0088726160931401 ], mean =  0.4571328 
Error in rbind(array(0, dim = c(n, p + q)), jacob) (from test02.R@8#11) : 
  number of columns of matrices must match (see arg 2)
> 
+ . + > r <- madlib.arima(ts, 1, 0, 1, include.mean = TRUE, max.iter = 100, tau = 1e-3, e1 = 1e-6, e2 = 1e-6, e3= 1e-6)
... init: phi = [ 0.00568186841206625 ], theta = [ 0.000124786351807415 ], mean =  0.4571328 
Error: object 'phi' not found
> 
+ + + . + + . + > 
+ . + > 
+ . + > r <- madlib.arima(ts, 1, 0, 1, include.mean = TRUE, max.iter = 100, tau = 1e-3, e1 = 1e-6, e2 = 1e-6, e3= 1e-6)
... init: phi = [ 0.0091807823558338 ], theta = [ 0.00276535238604993 ], mean =  0.4571328 
... iter  1 : phi = [ -0.385527160821696 ], theta = [ 0.359938922274305 ], mean =  0.4555341 
... iter  2 : phi = [ -0.778100616285829 ], theta = [ 0.741441558886866 ], mean =  0.4556966 
... iter  3 : phi = [ -0.935339592646925 ], theta = [ 0.924688239481378 ], mean =  0.4557093 
... iter  4 : phi = [ -0.943637247278365 ], theta = [ 0.952101551241592 ], mean =  0.4557476 
... iter  5 : phi = [ -0.941181298803568 ], theta = [ 0.950251939817931 ], mean =  0.4557545 
... iter  6 : phi = [ -0.94189955676405 ], theta = [ 0.951698458896609 ], mean =  0.4557572 
... iter  7 : phi = [ -0.941521629436253 ], theta = [ 0.951312991497818 ], mean =  0.4557586 
... iter  8 : phi = [ -0.94165698098921 ], theta = [ 0.951534219502685 ], mean =  0.4557593 
... iter  9 : phi = [ -0.941594399404739 ], theta = [ 0.951460342338038 ], mean =  0.4557596 
... iter  10 : phi = [ -0.941594399404739 ], theta = [ 0.951460342338038 ], mean =  0.4557596 
> s <- arima(ts, order = c(1,0,1), include.mean = TRUE, method = "CSS")
> s

Call:
arima(x = ts, order = c(1, 0, 1), include.mean = TRUE, method = "CSS")

Coefficients:
          ar1     ma1  intercept
      -0.9410  0.9513     0.4519
s.e.   0.0203  0.0342     0.0261

sigma^2 estimated as 0.07217:  part log likelihood = -10.56
> mean(ts)
[1] 0.4571328
> r <- madlib.arima(ts, 1, 0, 1, include.mean = FALSE, max.iter = 100, tau = 1e-3, e1 = 1e-6, e2 = 1e-6, e3= 1e-6)
... init: phi = [ 0.00636674555717036 ], theta = [ 0.00594599486561492 ], mean =  0 
... iter  1 : phi = [ 0.228147344412993 ], theta = [ 0.49574975019119 ], mean =  0 
... iter  2 : phi = [ 0.745390395594063 ], theta = [ -0.073335295966409 ], mean =  0 
... iter  3 : phi = [ 1.03717686460434 ], theta = [ -0.716955069277973 ], mean =  0 
... iter  4 : phi = [ 0.967268751031528 ], theta = [ -0.843105690473226 ], mean =  0 
... iter  5 : phi = [ 0.99708006376018 ], theta = [ -0.871975943603384 ], mean =  0 
... iter  6 : phi = [ 0.993392825345032 ], theta = [ -0.902654643300462 ], mean =  0 
... iter  7 : phi = [ 0.994822114437114 ], theta = [ -0.910424809384218 ], mean =  0 
... iter  8 : phi = [ 0.994913186959449 ], theta = [ -0.914147007256655 ], mean =  0 
... iter  9 : phi = [ 0.994992176615568 ], theta = [ -0.915445552695607 ], mean =  0 
... iter  10 : phi = [ 0.995020324820567 ], theta = [ -0.915949506602804 ], mean =  0 
... iter  11 : phi = [ 0.995031496207456 ], theta = [ -0.916144406479614 ], mean =  0 
... iter  12 : phi = [ 0.995035855826201 ], theta = [ -0.916220277644155 ], mean =  0 
... iter  13 : phi = [ 0.995037558854358 ], theta = [ -0.916249860127452 ], mean =  0 
... iter  14 : phi = [ 0.995038223788448 ], theta = [ -0.91626140303774 ], mean =  0 
... iter  15 : phi = [ 0.995038483381271 ], theta = [ -0.916265908265297 ], mean =  0 
... iter  16 : phi = [ 0.995038584722314 ], theta = [ -0.916267666860693 ], mean =  0 
... iter  17 : phi = [ 0.995038584722314 ], theta = [ -0.916267666860693 ], mean =  0 
> s <- arima(ts, order = c(1,0,1), include.mean = FALSE, method = "CSS")
> s

Call:
arima(x = ts, order = c(1, 0, 1), include.mean = FALSE, method = "CSS")

Coefficients:
        ar1      ma1
      0.995  -0.9163
s.e.  0.006   0.0503

sigma^2 estimated as 0.0905:  part log likelihood = -21.99
> var(r$z)
[1] 0.09125262
> var(r$z) * 100/101
[1] 0.09034913
> var(r$z) * 104/105
[1] 0.09038355
> var(r$z) * 201/202
[1] 0.09080087
> length(ts)
[1] 101
> s <- arima(ts, order = c(1,0,0), include.mean = FALSE, method = "CSS")
> s

Call:
arima(x = ts, order = c(1, 0, 0), include.mean = FALSE, method = "CSS")

Coefficients:
         ar1
      0.7094
s.e.  0.0689

sigma^2 estimated as 0.1397:  part log likelihood = -43.9
> include.mean <- TRUE
> r <- madlib.arima(ts, 1, 0, 0, include.mean = include.mean, max.iter = 100, tau = 1e-3, e1 = 1e-6, e2 = 1e-6, e3= 1e-6)
... init: phi = [ 0.00411257910309359 ], theta = [ 0 ], mean =  0.4571328 
... iter  1 : phi = [ -0.0327468357405603 ], theta = [ 0 ], mean =  0.4545882 
... iter  2 : phi = [ -0.0332068108099171 ], theta = [ 0 ], mean =  0.4546793 
... iter  3 : phi = [ -0.0332087323417195 ], theta = [ 0 ], mean =  0.4546793 
> s <- arima(ts, order = c(1,0,0), include.mean = include.mean, method = "CSS")
> s

Call:
arima(x = ts, order = c(1, 0, 0), include.mean = include.mean, method = "CSS")

Coefficients:
          ar1  intercept
      -0.0332     0.4547
s.e.   0.0999     0.0272

sigma^2 estimated as 0.07976:  part log likelihood = -15.61
> r <- madlib.arima(ts, 2, 0, 0, include.mean = include.mean, max.iter = 100, tau = 1e-3, e1 = 1e-6, e2 = 1e-6, e3= 1e-6)
... init: phi = [ 0.00107025685720146, 0.00582462414400652 ], theta = [ 0 ], mean =  0.4571328 
... iter  1 : phi = [ -0.0147689047122339, 0.099463800912765 ], theta = [ 0 ], mean =  0.4580738 
... iter  2 : phi = [ -0.0149133750981469, 0.100616687883278 ], theta = [ 0 ], mean =  0.4581481 
... iter  3 : phi = [ -0.0149137592565369, 0.100621440323482 ], theta = [ 0 ], mean =  0.4581482 
> s <- arima(ts, order = c(2,0,0), include.mean = include.mean, method = "CSS")
> s

Call:
arima(x = ts, order = c(2, 0, 0), include.mean = include.mean, method = "CSS")

Coefficients:
          ar1     ar2  intercept
      -0.0149  0.1006     0.4581
s.e.   0.0989  0.0988     0.0304

sigma^2 estimated as 0.07806:  part log likelihood = -14.52
> s <- arima(ts, order = c(0,0,1), include.mean = include.mean, method = "CSS")
> s

Call:
arima(x = ts, order = c(0, 0, 1), include.mean = include.mean, method = "CSS")

Coefficients:
          ma1  intercept
      -0.0278     0.4572
s.e.   0.0917     0.0273

sigma^2 estimated as 0.07969:  part log likelihood = -15.57
> r <- madlib.arima(ts, 0, 0, 1, include.mean = include.mean, max.iter = 100, tau = 1e-3, e1 = 1e-6, e2 = 1e-6, e3= 1e-6)
... init: phi = [ 0 ], theta = [ 0.0083928246400319 ], mean =  0.4571328 
... iter  1 : phi = [ 0 ], theta = [ -0.0206841962964726 ], mean =  0.4544967 
... iter  2 : phi = [ 0 ], theta = [ -0.0151677256333553 ], mean =  0.4545301 
... iter  3 : phi = [ 0 ], theta = [ -0.0162205826237614 ], mean =  0.4545339 
... iter  4 : phi = [ 0 ], theta = [ -0.0160176448982027 ], mean =  0.4545331 
... iter  5 : phi = [ 0 ], theta = [ -0.0160571360379279 ], mean =  0.4545333 
... iter  6 : phi = [ 0 ], theta = [ -0.0160528678650714 ], mean =  0.4545332 
... iter  7 : phi = [ 0 ], theta = [ -0.0160528678650714 ], mean =  0.4545332 
> r <- madlib.arima(ts, 0, 0, 1, include.mean = include.mean, max.iter = 100, tau = 1e-3, e1 = 1e-8, e2 = 1e-8, e3= 1e-8)
... init: phi = [ 0 ], theta = [ 0.00237061184598133 ], mean =  0.4571328 
... iter  1 : phi = [ 0 ], theta = [ -0.0195929581931641 ], mean =  0.4544966 
... iter  2 : phi = [ 0 ], theta = [ -0.0153741628992769 ], mean =  0.454531 
... iter  3 : phi = [ 0 ], theta = [ -0.0161810442098671 ], mean =  0.4545338 
... iter  4 : phi = [ 0 ], theta = [ -0.0160253037025378 ], mean =  0.4545331 
... iter  5 : phi = [ 0 ], theta = [ -0.0160556411877539 ], mean =  0.4545332 
... iter  6 : phi = [ 0 ], theta = [ -0.0160523413451266 ], mean =  0.4545332 
... iter  7 : phi = [ 0 ], theta = [ -0.0160523413451266 ], mean =  0.4545332 
> 
+ + . + + . + + . + > r <- madlib.arima(ts, 0, 0, 1, include.mean = include.mean, max.iter = 100, tau = 1e-3, e1 = 1e-8, e2 = 1e-8, e3= 1e-8)
... init: phi = [ 0 ], theta = [ 0.00323226878186688 ], mean =  0 
... iter  1 : phi = [ 0 ], theta = [ 0.00641811848813466 ], mean =  0.4511235 
... iter  2 : phi = [ 0 ], theta = [ -0.0202408752117036 ], mean =  0.4546115 
... iter  3 : phi = [ 0 ], theta = [ -0.0152255131862222 ], mean =  0.4545287 
... iter  4 : phi = [ 0 ], theta = [ -0.016214330600839 ], mean =  0.4545339 
... iter  5 : phi = [ 0 ], theta = [ -0.016018104335466 ], mean =  0.4545331 
... iter  6 : phi = [ 0 ], theta = [ -0.0160571739883889 ], mean =  0.4545333 
... iter  7 : phi = [ 0 ], theta = [ -0.0160509640987417 ], mean =  0.4545332 
... iter  8 : phi = [ 0 ], theta = [ -0.0160509640987417 ], mean =  0.4545332 
> r <- madlib.arima(ts, 0, 0, 1, include.mean = include.mean, max.iter = 100, tau = 1e-3, e1 = 1e-8, e2 = 1e-8, e3= 1e-8)
... init: phi = [ 0 ], theta = [ 0.00235852980054915 ], mean =  0 
... iter  1 : phi = [ 0 ], theta = [ 0.00661560325560226 ], mean =  0.4510316 
... iter  2 : phi = [ 0 ], theta = [ -0.0202738669238508 ], mean =  0.4546134 
... iter  3 : phi = [ 0 ], theta = [ -0.0152190253440494 ], mean =  0.4545286 
... iter  4 : phi = [ 0 ], theta = [ -0.0162156259075778 ], mean =  0.4545339 
... iter  5 : phi = [ 0 ], theta = [ -0.0160178450586394 ], mean =  0.4545331 
... iter  6 : phi = [ 0 ], theta = [ -0.0160572259555085 ], mean =  0.4545333 
... iter  7 : phi = [ 0 ], theta = [ -0.0160509603293287 ], mean =  0.4545332 
... iter  8 : phi = [ 0 ], theta = [ -0.0160509603293287 ], mean =  0.4545332 
> s$residuals
Time Series:
Start = 1 
End = 101 
Frequency = 1 
  [1]  0.2659994936 -0.4109495695  0.0283382814 -0.3639617281  0.0154262584
  [6] -0.3794589348  0.1563738057 -0.4371088017  0.3822250238 -0.1795081510
 [11] -0.2126165611 -0.4147293529  0.4315633008  0.1652418417  0.2322825821
 [16] -0.2508870850  0.4028746713  0.2729350046 -0.2281906934  0.2935655479
 [21]  0.1965900941 -0.1104487905  0.0498567163 -0.2177423534  0.1973963425
 [26] -0.1347623696 -0.3057695855 -0.1469297345  0.2737545854  0.0922180939
 [31]  0.3314577973  0.0102229442  0.1237182147 -0.1707340936  0.0886831341
 [36] -0.3913864713 -0.1077711318 -0.2854740053 -0.3860733764 -0.2560770527
 [41] -0.0225602592 -0.1292208826 -0.2005854656 -0.1207551167  0.4784643384
 [46]  0.5011667692  0.0985787549  0.3515808524  0.2165451532  0.3120586702
 [51]  0.1145945702 -0.1444434368 -0.3567201249 -0.3938996043  0.0794627390
 [56]  0.3101237741 -0.0584416309  0.2439349787 -0.3665635381 -0.3422436500
 [61] -0.2221763183  0.4065433857  0.1374268673  0.3717622393 -0.2939488824
 [66] -0.3314466197  0.4220463771  0.0677281556 -0.1467002650  0.5062148262
 [71]  0.2818935253  0.3009819146 -0.1527636165  0.5237514562 -0.3503035495
 [76] -0.2318773649  0.4665882373  0.1899243152 -0.4108489403  0.1255546898
 [81] -0.0563470197  0.1453947392  0.4505588257  0.0571531983  0.2217369606
 [86]  0.0002639871 -0.1902796322 -0.3950340613 -0.3141519079 -0.1151946411
 [91] -0.2678301553 -0.0661078833 -0.2384094298  0.3120400909 -0.2248759920
 [96] -0.0899363990  0.4500625271 -0.3326086748  0.4202345549 -0.2271681020
[101] -0.3839719354
> r$z
  [1] -0.4157071797  0.0357267082 -0.3615391360  0.0223779173 -0.3768916617
  [6]  0.1635098493 -0.4361944326  0.3900118121 -0.1812366557 -0.2078985073
 [11] -0.4095188653  0.4391561303  0.1629305936  0.2329411308 -0.2509684685
 [16]  0.4084577286  0.2709285342 -0.2287924410  0.2988736138  0.1958633824
 [21] -0.1101330904  0.0537962664 -0.2156279194  0.2026252578 -0.1343605478
 [26] -0.3015430151 -0.1406327662  0.2782187219  0.0917105772  0.3330031867
 [31]  0.0089906767  0.1262152569 -0.1695105443  0.0933454929 -0.3897165715
 [36] -0.1005093662 -0.2814544215 -0.3800181646 -0.2488073173 -0.0167982372
 [41] -0.1262264355 -0.1963823828 -0.1156942372  0.4826011328  0.4982490512
 [46]  0.0952810952  0.3530067317  0.2150745601  0.3121279966  0.1135665130
 [51] -0.1431692833 -0.3523658188 -0.3870020145  0.0868379386  0.3119455396
 [56] -0.0594188285  0.2472427921 -0.3667392916 -0.3353031308 -0.2154072882
 [61]  0.4118991022  0.1353736475  0.3727517021 -0.2956635730 -0.3253838849
 [66]  0.4286744735  0.0655132283 -0.1448945715  0.5106041775  0.2786538460
 [71]  0.3002551274 -0.1536743214  0.5281684395 -0.3537488070 -0.2251803481
 [76]  0.4720567667  0.1871674943 -0.4104875153  0.1330240999 -0.0550652341
 [81]  0.1487142038  0.4515409181  0.0545126805  0.2236600585  0.0003267917
 [86] -0.1876448042 -0.3901194275 -0.3067952090 -0.1087489550 -0.2637364583
 [91] -0.0602587633 -0.2349019836  0.3175341639 -0.2258167585 -0.0846727161
 [96]  0.4538405158 -0.3351984852  0.4267374216 -0.2293637539 -0.3787014667
> sum(ts[2:101]) - sum(s$residuals[2:101]) - s$coef[1] * sum(s$residuals[1:100])
     ma1 
45.71701 
> s

Call:
arima(x = ts, order = c(0, 0, 1), include.mean = include.mean, method = "CSS")

Coefficients:
          ma1  intercept
      -0.0278     0.4572
s.e.   0.0917     0.0273

sigma^2 estimated as 0.07969:  part log likelihood = -15.57
> z <- c(0, r$z)
> length(z)
[1] 101
> sum(ts[2:101]) - sum(z[2:101]) - (-0.0160509603293287) * sum(z[1:100])
[1] 45.45332
> data(camp)
> ts <- camp
> legnth(ts)
Error: could not find function "legnth"
> length(ts)
[1] 5405
> r <- madlib.arima(ts, 0, 0, 1, include.mean = include.mean, max.iter = 100, tau = 1e-3, e1 = 1e-8, e2 = 1e-8, e3= 1e-8)
... init: phi = [ 0 ], theta = [ 0.0007794418791309 ], mean =  0 
... iter  1 : phi = [ 0 ], theta = [ 0.967631064281094 ], mean =  0.4941994 
... iter  2 : phi = [ 0 ], theta = [ 0.936455183580571 ], mean =  7.883623 
... iter  3 : phi = [ 0 ], theta = [ 0.878805839492619 ], mean =  14.82094 
... iter  4 : phi = [ 0 ], theta = [ 0.785008482195841 ], mean =  20.95632 
... iter  5 : phi = [ 0 ], theta = [ 0.675619163338595 ], mean =  26.16438 
... iter  6 : phi = [ 0 ], theta = [ 0.615768710604048 ], mean =  30.31972 
... iter  7 : phi = [ 0 ], theta = [ 0.579894563484486 ], mean =  33.5424 
... iter  8 : phi = [ 0 ], theta = [ 0.547722955944347 ], mean =  36.01932 
... iter  9 : phi = [ 0 ], theta = [ 0.529130119548009 ], mean =  37.88505 
... iter  10 : phi = [ 0 ], theta = [ 0.517512996592728 ], mean =  39.26628 
... iter  11 : phi = [ 0 ], theta = [ 0.512064354342595 ], mean =  40.26667 
... iter  12 : phi = [ 0 ], theta = [ 0.509249927311523 ], mean =  40.9745 
... iter  13 : phi = [ 0 ], theta = [ 0.508166728353166 ], mean =  41.46187 
... iter  14 : phi = [ 0 ], theta = [ 0.507661338016338 ], mean =  41.78744 
... iter  15 : phi = [ 0 ], theta = [ 0.507514159170295 ], mean =  41.99762 
... iter  16 : phi = [ 0 ], theta = [ 0.507444468967647 ], mean =  42.12821 
... iter  17 : phi = [ 0 ], theta = [ 0.507434699253524 ], mean =  42.20592 
... iter  18 : phi = [ 0 ], theta = [ 0.507426325140302 ], mean =  42.24998 
... iter  19 : phi = [ 0 ], theta = [ 0.507427633952802 ], mean =  42.27363 
... iter  20 : phi = [ 0 ], theta = [ 0.507426249378221 ], mean =  42.28556 
... iter  21 : phi = [ 0 ], theta = [ 0.507426955515731 ], mean =  42.29117 
... iter  22 : phi = [ 0 ], theta = [ 0.507426573170321 ], mean =  42.29345 
... iter  23 : phi = [ 0 ], theta = [ 0.507426798776413 ], mean =  42.29428 
... iter  24 : phi = [ 0 ], theta = [ 0.50742667574853 ], mean =  42.29456 
... iter  25 : phi = [ 0 ], theta = [ 0.507426746370116 ], mean =  42.29466 
... iter  26 : phi = [ 0 ], theta = [ 0.507426707078141 ], mean =  42.29469 
... iter  27 : phi = [ 0 ], theta = [ 0.507426729353618 ], mean =  42.2947 
... iter  28 : phi = [ 0 ], theta = [ 0.507426716866415 ], mean =  42.29471 
... iter  29 : phi = [ 0 ], theta = [ 0.507426723913759 ], mean =  42.29471 
... iter  30 : phi = [ 0 ], theta = [ 0.507426719952454 ], mean =  42.29471 
... iter  31 : phi = [ 0 ], theta = [ 0.507426722184462 ], mean =  42.29471 
... iter  32 : phi = [ 0 ], theta = [ 0.507426720928638 ], mean =  42.29471 
... iter  33 : phi = [ 0 ], theta = [ 0.507426721635827 ], mean =  42.29471 
... iter  34 : phi = [ 0 ], theta = [ 0.507426721237795 ], mean =  42.29471 
... iter  35 : phi = [ 0 ], theta = [ 0.507426721237795 ], mean =  42.29471 
> s <- arima(ts, order = c(0,0,1), include.mean = include.mean, method = "CSS")
> s

Call:
arima(x = ts, order = c(0, 0, 1), include.mean = include.mean, method = "CSS")

Coefficients:
         ma1  intercept
      0.5074    42.2928
s.e.  0.0094     0.1991

sigma^2 estimated as 94.33:  part log likelihood = -19957.02
> mean(ts)
[1] 42.29288
> r <- madlib.arima(ts, 0, 0, 1, include.mean = include.mean, max.iter = 100, tau = 1e-3, e1 = 1e-10, e2 = 1e-10, e3= 1e-10)
... init: phi = [ 0 ], theta = [ 0.0014010389870964 ], mean =  0 
... iter  1 : phi = [ 0 ], theta = [ 0.968741574854315 ], mean =  0.4962925 
... iter  2 : phi = [ 0 ], theta = [ 0.938567244294609 ], mean =  7.889133 
... iter  3 : phi = [ 0 ], theta = [ 0.882492051662177 ], mean =  14.85777 
... iter  4 : phi = [ 0 ], theta = [ 0.789982244665179 ], mean =  21.02869 
... iter  5 : phi = [ 0 ], theta = [ 0.678038832999536 ], mean =  26.27351 
... iter  6 : phi = [ 0 ], theta = [ 0.61293856076558 ], mean =  30.46109 
... iter  7 : phi = [ 0 ], theta = [ 0.578239539873188 ], mean =  33.69089 
... iter  8 : phi = [ 0 ], theta = [ 0.545761056030875 ], mean =  36.16253 
... iter  9 : phi = [ 0 ], theta = [ 0.527959356438952 ], mean =  38.01339 
... iter  10 : phi = [ 0 ], theta = [ 0.516685205512014 ], mean =  39.37543 
... iter  11 : phi = [ 0 ], theta = [ 0.511667986326141 ], mean =  40.35511 
... iter  12 : phi = [ 0 ], theta = [ 0.509026045675443 ], mean =  41.04308 
... iter  13 : phi = [ 0 ], theta = [ 0.508081234137922 ], mean =  41.51274 
... iter  14 : phi = [ 0 ], theta = [ 0.507618401566357 ], mean =  41.82354 
... iter  15 : phi = [ 0 ], theta = [ 0.507502583576725 ], mean =  42.02205 
... iter  16 : phi = [ 0 ], theta = [ 0.507438389785702 ], mean =  42.14394 
... iter  17 : phi = [ 0 ], theta = [ 0.507434170933552 ], mean =  42.21551 
... iter  18 : phi = [ 0 ], theta = [ 0.507425560656939 ], mean =  42.25549 
... iter  19 : phi = [ 0 ], theta = [ 0.507427829829855 ], mean =  42.27659 
... iter  20 : phi = [ 0 ], theta = [ 0.507426104903954 ], mean =  42.28703 
... iter  21 : phi = [ 0 ], theta = [ 0.507427037775516 ], mean =  42.29183 
... iter  22 : phi = [ 0 ], theta = [ 0.507426529746757 ], mean =  42.2937 
... iter  23 : phi = [ 0 ], theta = [ 0.507426824402629 ], mean =  42.29437 
... iter  24 : phi = [ 0 ], theta = [ 0.507426661736474 ], mean =  42.29459 
... iter  25 : phi = [ 0 ], theta = [ 0.507426754399103 ], mean =  42.29467 
... iter  26 : phi = [ 0 ], theta = [ 0.507426702605854 ], mean =  42.2947 
... iter  27 : phi = [ 0 ], theta = [ 0.507426731887312 ], mean =  42.29471 
... iter  28 : phi = [ 0 ], theta = [ 0.507426715445482 ], mean =  42.29471 
... iter  29 : phi = [ 0 ], theta = [ 0.507426724715484 ], mean =  42.29471 
... iter  30 : phi = [ 0 ], theta = [ 0.507426719501737 ], mean =  42.29471 
... iter  31 : phi = [ 0 ], theta = [ 0.507426722438397 ], mean =  42.29471 
... iter  32 : phi = [ 0 ], theta = [ 0.507426720785756 ], mean =  42.29471 
... iter  33 : phi = [ 0 ], theta = [ 0.507426721716285 ], mean =  42.29471 
... iter  34 : phi = [ 0 ], theta = [ 0.507426721192509 ], mean =  42.29471 
... iter  35 : phi = [ 0 ], theta = [ 0.507426721487387 ], mean =  42.29471 
... iter  36 : phi = [ 0 ], theta = [ 0.507426721321393 ], mean =  42.29471 
... iter  37 : phi = [ 0 ], theta = [ 0.507426721414841 ], mean =  42.29471 
... iter  38 : phi = [ 0 ], theta = [ 0.507426721362236 ], mean =  42.29471 
... iter  39 : phi = [ 0 ], theta = [ 0.507426721362236 ], mean =  42.29471 
> z <- c(0, r$z)
> sum(ts[2:length(ts)]) - sum(z[2:length(ts)]) - (0.507426721362236) * sum(z[1:(length(ts)-1)])
[1] 228560.6
> (sum(ts[2:length(ts)]) - sum(z[2:length(ts)]) - (0.507426721362236) * sum(z[1:(length(ts)-1)])) / (length(ts) - 1)
> (sum(ts[2:length(ts)]) - sum(z[2:length(ts)]) - (0.507426721362236) * sum(z[1:(length(ts)-1)])) / (length(ts) - 1)
[1] 42.29471                                                                          

> (sum(ts[2:length(ts)]) - sum(z[2:length(ts)]) - (0.507426721362236) * sum(z[1:(length(ts)-1)])) / (length(ts) - 1)
Error: unexpected '>' in ">"
> [1] 42.29471                                                                          
Error: unexpected '[' in "["
> w <- s$residuals
> > (sum(ts[2:length(ts)]) - sum(z[2:length(ts)]) - (0.507426721362236) * sum(z[1:(length(ts)-1)])) / (length(ts) - 1)
Error: unexpected '>' in ">"
>   C-c C-c
> 
[1] 42.29471                                                                          


> [1] 42.29471                                                                          
Error: unexpected '[' in "["
> 
> (sum(ts[2:length(ts)]) - sum(w[2:length(ts)]) - (s$coef[1]) * sum(w[1:(length(ts)-1)])) / (length(ts) - 1)
     ma1 
42.29281 
> s

Call:
arima(x = ts, order = c(0, 0, 1), include.mean = include.mean, method = "CSS")

Coefficients:
         ma1  intercept
      0.5074    42.2928
s.e.  0.0094     0.1991

sigma^2 estimated as 94.33:  part log likelihood = -19957.02
> 0.97^8
[1] 0.7837434
> library(PivotalR)
Loading required package: Matrix
Loading required package: lattice
## connect to HAWQ

To launch the graphical user interface, run the function pivotalr() !

Attaching package: ‘PivotalR’

The following object is masked from ‘package:stats’:

    sd, var

> 
> db.connect(port = 18526, dbname = "madlib")
Loading required package: DBI
Created a connection to database with ID 1 
[1] 1
> ## connect to DCA
> db.connect(host = "dca1-mdw1.dan.dh.greenplum.com", user = "gpadmin",
+            password = "changeme", dbname = "dstraining")
Created a connection to database with ID 2 
[1] 2
> ## wrapper of a table in connection 1
> x <- db.data.frame("madlibtestdata.dt_abalone")
An R object pointing to madlibtestdata.dt_abalone in connection 1 is created !
> x
Table      :    "madlibtestdata"."dt_abalone"
Database   :    madlib
Host       :    localhost
Connection :    1
> ## wrapper of a table in connection 2
> y <- db.data.frame("madlibtestdata.dt_abalone", conn.id = 2)
An R object pointing to madlibtestdata.dt_abalone in connection 2 is created !
> fit <- generic.bagging(function(data) {
+                            madlib.lm(rings ~ . - id - sex, data = data)
+                        },
+                        data = y, nbags = 10, fraction = 0.85)
library(PivotalR)
library(PivotalR)
